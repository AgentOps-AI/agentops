{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Anthropic supports both sync and async! This is great because we can wait for functions to finish before we use them! \n\nIn this example, we will make a program called \"Titan Support Protocol.\" In this example, we will assign our mech a personality type and have a message generated based on our Titan's health (Which we randomly choose). We also send four generated UUIDs which are generated while the LLM runs","metadata":{}},{"cell_type":"markdown","source":"First, we start by importing Agentops and Anthropic","metadata":{}},{"cell_type":"code","source":"!pip install agentops\n!pip install anthropic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setup our generic default statements","metadata":{}},{"cell_type":"code","source":"from anthropic import Anthropic, AsyncAnthropic\nimport agentops\nimport os\nimport random #We don't need this for agentops, we use this to generate a message later\nimport asyncio #We don't need this for agentops, we use this to run both async tasks and await them both finishing later\nimport uuid #We don't need this for agentops, we use this to generate UUIDs\nfrom dotenv import load_dotenv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And set our API keys.","metadata":{}},{"cell_type":"code","source":"load_dotenv()\nANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\") or \"<your_anthropic_key>\"\nAGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\") or \"<your_agentops_key>\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nNow let's set the client as Anthropic","metadata":{}},{"cell_type":"code","source":"client = Anthropic()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we create three personality presets; \n\nLegion is a relentless and heavy-hitting Titan that embodies brute strength and defensive firepower, Northstar is a precise and agile sniper that excels in long-range combat and flight, while Ronin is a swift and aggressive melee specialist who thrives on close-quarters hit-and-run tactics.","metadata":{}},{"cell_type":"code","source":"TitanPersonality = [\n    \"Legion is a relentless and heavy-hitting Titan that embodies brute strength and defensive firepower. He speaks bluntly.,\", \n    \"Northstar is a precise and agile sniper that excels in long-range combat and flight. He speaks with an edge of coolness to him\", \n    \"Ronin is a swift and aggressive melee specialist who thrives on close-quarters hit-and-run tactics. He talks like a Samurai might.\"\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And our comabt log generator! We select from four health presets!","metadata":{}},{"cell_type":"code","source":"TitanHealth = [\n    \"Fully functional\", \"Slightly Damaged\", \"Moderate Damage\", \"Considerable Damage\", \"Near Destruction\"\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now to the real core of this; making our message stream! We create this as a function we can call later! I personally made user (Sends an initialization prompt), computer (sends the titan personality and health) and assistant (The LLM itself). I also create examples since the LLM's context size can handle it!","metadata":{}},{"cell_type":"code","source":"async def req() -> None:\n    message = await client.messages.create(\n        max_tokens=1024,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"You are a Titan; a mech from Titanfall 2. Based on your titan's personality and status, generate a message for your pilot. If Near Destruction, make an all caps death message such as AVENGE ME or UNTIL NEXT TIME.\"\n            },\n            {\n                \"role\": \"computer\",\n                \"content\": \"Personality: Legion is a relentless and heavy-hitting Titan that embodies brute strength and defensive firepower. He speaks bluntly. Status: Considerable Damage\"\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": \"Heavy damage detected. Reinforcements would be appreciated, but I can still fight.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": \"You are a Titan; a mech from Titanfall 2. Based on your titan's personality and status, generate a message for your pilot. If Near Destruction, make an all caps death message such as AVENGE ME or UNTIL NEXT TIME.\"\n            },\n            {\n                \"role\": \"computer\",\n                \"content\": f\"Personality: {random.choice(TitanPersonality)}. Status: {random.choice(TitanHealth)}\"\n            }\n        ],\n        model=\"claude-3-5-sonnet-20240620\",\n    )\n    llmgentext = (message.content[0].text)\n    \n    \nuuids = []\n    \nasync def generate_uuids():\n    # Generate 4 UUIDs and print them vertically while we await the LLM's finish\n    uuids = [str(uuid.uuid4()) for _ in range(4)]\n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we wrap it all in a nice main function!Run this for the magic to happen! Go to your AgentOps dashboard and you should see this session reflected!\n","metadata":{}},{"cell_type":"code","source":"# Start both at the same time and wait\nawait asyncio.gather(generate_uuids(), req())\n    \nprint(\"Combat log incoming from encrypted area \")\nfor u in uuids:\n        print(u)\n\nprint(\". Log Reads:\", llmgentext)\n\nagentops.end_session(\"Success\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run this for the magic to happen! Go to your AgentOps dashboard and you should see this session reflected!","metadata":{}}]}