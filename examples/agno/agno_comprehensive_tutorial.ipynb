{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agno agentops python-dotenv openai cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import Iterator\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import agno components\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.team import Team\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.workflow import Workflow\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "from agno.tools.reasoning import ReasoningTools\n",
    "from agno.tools.arxiv import ArxivTools\n",
    "from agno.tools.googlesearch import GoogleSearchTools\n",
    "from agno.knowledge.url import UrlKnowledge\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from agno.utils.log import logger\n",
    "from agno.vectordb.lancedb import LanceDb\n",
    "from agno.vectordb.search import SearchType\n",
    "from agno.embedder.cohere import CohereEmbedder\n",
    "from agno.reranker.cohere import CohereReranker\n",
    "\n",
    "import agentops\n",
    "\n",
    "# Initialize AgentOps\n",
    "agentops.init(api_key=os.getenv(\"AGENTOPS_API_KEY\"))\n",
    "\n",
    "# Configuration\n",
    "MODEL_ID = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_environment():\n",
    "    \"\"\"Check if required environment variables are set.\"\"\"\n",
    "    required_vars = [\"AGENTOPS_API_KEY\", \"OPENAI_API_KEY\"]\n",
    "    missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "    if missing_vars:\n",
    "        print(f\"Missing required environment variables: {missing_vars}\")\n",
    "        print(\"Please set these in your .env file or environment\")\n",
    "        return False\n",
    "\n",
    "    print(\"Environment variables checked successfully\")\n",
    "    return True\n",
    "\n",
    "# Check environment\n",
    "check_environment()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Basic Agents and Teams\n",
    "\n",
    "Let's start with creating individual agents and organizing them into teams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_basic_agents():\n",
    "    \"\"\"Demonstrate basic agent creation and team coordination.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC AGENTS AND TEAMS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Create individual agents\n",
    "        news_agent = Agent(name=\"News Agent\", role=\"Get the latest news\", model=OpenAIChat(id=MODEL_ID))\n",
    "\n",
    "        weather_agent = Agent(\n",
    "            name=\"Weather Agent\", role=\"Get the weather for the next 7 days\", model=OpenAIChat(id=MODEL_ID)\n",
    "        )\n",
    "\n",
    "        # Create a team with coordination mode\n",
    "        team = Team(name=\"News and Weather Team\", mode=\"coordinate\", members=[news_agent, weather_agent])\n",
    "\n",
    "        # Run team task\n",
    "        response = team.run(\"What is the weather in Tokyo?\")\n",
    "        print(f\"Team Response: {response.content}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Basic agents error: {e}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_basic_agents()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Tool Integration with RAG\n",
    "\n",
    "This section demonstrates how to integrate tools with knowledge bases for Retrieval-Augmented Generation (RAG).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_tool_integration():\n",
    "    \"\"\"Demonstrate tool integration with RAG and knowledge base.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TOOL INTEGRATION WITH RAG\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Create knowledge base with vector database\n",
    "        knowledge_base = UrlKnowledge(\n",
    "            urls=[\"https://docs.agno.com/introduction/agents.md\"],\n",
    "            # Use LanceDB as the vector database, store embeddings in the `agno_docs` table\n",
    "            vector_db=LanceDb(\n",
    "                uri=\"tmp/lancedb\",\n",
    "                table_name=\"agno_docs\",\n",
    "                search_type=SearchType.hybrid,\n",
    "                embedder=CohereEmbedder(id=\"embed-v4.0\"),\n",
    "                reranker=CohereReranker(model=\"rerank-v3.5\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Create agent with knowledge and reasoning tools\n",
    "        agent = Agent(\n",
    "            model=OpenAIChat(id=MODEL_ID),\n",
    "            # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.\n",
    "            knowledge=knowledge_base,\n",
    "            # search_knowledge=True gives the Agent the ability to search on demand\n",
    "            search_knowledge=True,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            instructions=[\n",
    "                \"Include sources in your response.\",\n",
    "                \"Always search your knowledge before answering the question.\",\n",
    "                \"Only include the output in your response. No other text.\",\n",
    "            ],\n",
    "            markdown=True,\n",
    "        )\n",
    "\n",
    "        print(\"Running RAG agent with knowledge base...\")\n",
    "        agent.print_response(\n",
    "            \"What are Agents?\",\n",
    "            show_full_reasoning=True,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Tool integration error: {e}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_tool_integration()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Workflows with Caching\n",
    "\n",
    "This section demonstrates how to create workflows that cache previous outputs for improved performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheWorkflow(Workflow):\n",
    "    \"\"\"A workflow that demonstrates caching capabilities.\"\"\"\n",
    "\n",
    "    # Purely descriptive, not used by the workflow\n",
    "    description: str = \"A workflow that caches previous outputs\"\n",
    "\n",
    "    # Add agents or teams as attributes on the workflow\n",
    "    agent = Agent(model=OpenAIChat(id=MODEL_ID))\n",
    "\n",
    "    # Write the logic in the `run()` method\n",
    "    def run(self, message: str) -> Iterator[RunResponse]:\n",
    "        logger.info(f\"Checking cache for '{message}'\")\n",
    "        # Check if the output is already cached\n",
    "        if self.session_state.get(message):\n",
    "            logger.info(f\"Cache hit for '{message}'\")\n",
    "            yield RunResponse(run_id=self.run_id, content=self.session_state.get(message))\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Cache miss for '{message}'\")\n",
    "        # Run the agent and yield the response\n",
    "        yield from self.agent.run(message, stream=True)\n",
    "\n",
    "        # Cache the output after response is yielded\n",
    "        self.session_state[message] = self.agent.run_response.content\n",
    "\n",
    "\n",
    "def demonstrate_workflows():\n",
    "    \"\"\"Demonstrate workflow capabilities with caching.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"WORKFLOWS WITH CACHING\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        workflow = CacheWorkflow()\n",
    "\n",
    "        print(\"First run (cache miss):\")\n",
    "        # Run workflow (this takes ~1s)\n",
    "        response: Iterator[RunResponse] = workflow.run(message=\"Tell me a joke.\")\n",
    "        # Print the response\n",
    "        pprint_run_response(response, markdown=True, show_time=True)\n",
    "\n",
    "        print(\"\\nSecond run (cache hit):\")\n",
    "        # Run workflow again (this is immediate because of caching)\n",
    "        response: Iterator[RunResponse] = workflow.run(message=\"Tell me a joke.\")\n",
    "        # Print the response\n",
    "        pprint_run_response(response, markdown=True, show_time=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Workflow error: {e}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_workflows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Collaborative Research Teams\n",
    "\n",
    "This section demonstrates how to create teams of specialized research agents that collaborate on complex research tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_research_team():\n",
    "    \"\"\"Demonstrate collaborative research team with multiple specialized agents.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COLLABORATIVE RESEARCH TEAM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Create specialized research agents\n",
    "        reddit_researcher = Agent(\n",
    "            name=\"Reddit Researcher\",\n",
    "            role=\"Research a topic on Reddit\",\n",
    "            model=OpenAIChat(id=\"gpt-4o\"),\n",
    "            tools=[GoogleSearchTools()],\n",
    "            add_name_to_instructions=True,\n",
    "            instructions=dedent(\n",
    "                \"\"\"\n",
    "                You are a Reddit researcher.\n",
    "                You will be given a topic to research on Reddit.\n",
    "                You will need to find the most relevant posts on Reddit.\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hackernews_researcher = Agent(\n",
    "            name=\"HackerNews Researcher\",\n",
    "            model=OpenAIChat(\"gpt-4o\"),\n",
    "            role=\"Research a topic on HackerNews.\",\n",
    "            tools=[HackerNewsTools()],\n",
    "            add_name_to_instructions=True,\n",
    "            instructions=dedent(\n",
    "                \"\"\"\n",
    "                You are a HackerNews researcher.\n",
    "                You will be given a topic to research on HackerNews.\n",
    "                You will need to find the most relevant posts on HackerNews.\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        academic_paper_researcher = Agent(\n",
    "            name=\"Academic Paper Researcher\",\n",
    "            model=OpenAIChat(\"gpt-4o\"),\n",
    "            role=\"Research academic papers and scholarly content\",\n",
    "            tools=[GoogleSearchTools(), ArxivTools()],\n",
    "            add_name_to_instructions=True,\n",
    "            instructions=dedent(\n",
    "                \"\"\"\n",
    "                You are an academic paper researcher.\n",
    "                You will be given a topic to research in academic literature.\n",
    "                You will need to find relevant scholarly articles, papers, and academic discussions.\n",
    "                Focus on peer-reviewed content and citations from reputable sources.\n",
    "                Provide brief summaries of key findings and methodologies.\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        twitter_researcher = Agent(\n",
    "            name=\"Twitter Researcher\",\n",
    "            model=OpenAIChat(\"gpt-4o\"),\n",
    "            role=\"Research trending discussions and real-time updates\",\n",
    "            tools=[DuckDuckGoTools()],\n",
    "            add_name_to_instructions=True,\n",
    "            instructions=dedent(\n",
    "                \"\"\"\n",
    "                You are a Twitter/X researcher.\n",
    "                You will be given a topic to research on Twitter/X.\n",
    "                You will need to find trending discussions, influential voices, and real-time updates.\n",
    "                Focus on verified accounts and credible sources when possible.\n",
    "                Track relevant hashtags and ongoing conversations.\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Create collaborative team\n",
    "        agent_team = Team(\n",
    "            name=\"Discussion Team\",\n",
    "            mode=\"collaborate\",\n",
    "            model=OpenAIChat(\"gpt-4o\"),\n",
    "            members=[\n",
    "                reddit_researcher,\n",
    "                hackernews_researcher,\n",
    "                academic_paper_researcher,\n",
    "                twitter_researcher,\n",
    "            ],\n",
    "            instructions=[\n",
    "                \"You are a discussion master.\",\n",
    "                \"You have to stop the discussion when you think the team has reached a consensus.\",\n",
    "            ],\n",
    "            success_criteria=\"The team has reached a consensus.\",\n",
    "            enable_agentic_context=True,\n",
    "            add_context=True,\n",
    "            show_tool_calls=True,\n",
    "            markdown=True,\n",
    "            debug_mode=True,\n",
    "            show_members_responses=True,\n",
    "        )\n",
    "\n",
    "        print(\"Running collaborative research team...\")\n",
    "        agent_team.print_response(\n",
    "            message=\"Start the discussion on the topic: 'What is the best way to learn to code?'\",\n",
    "            stream=True,\n",
    "            stream_intermediate_steps=True,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Research team error: {e}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_research_team()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Async Operations\n",
    "\n",
    "This section demonstrates how to run multiple agent operations concurrently using async/await patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_async_operations():\n",
    "    \"\"\"Demonstrate async operations with Agno agents.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ASYNC OPERATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # Create async tasks with different agents\n",
    "        agent = Agent(model=OpenAIChat(id=MODEL_ID))\n",
    "\n",
    "        # Define async tasks\n",
    "        async def task1():\n",
    "            response = await agent.arun(\"Explain Python in one paragraph\")\n",
    "            return f\"Task 1: {response.content}\"\n",
    "\n",
    "        async def task2():\n",
    "            response = await agent.arun(\"Explain JavaScript in one paragraph\")\n",
    "            return f\"Task 2: {response.content}\"\n",
    "\n",
    "        async def task3():\n",
    "            response = await agent.arun(\"Compare them briefly\")\n",
    "            return f\"Task 3: {response.content}\"\n",
    "\n",
    "        # Run tasks concurrently\n",
    "        print(\"Running async tasks concurrently...\")\n",
    "        results = await asyncio.gather(task1(), task2(), task3())\n",
    "\n",
    "        for result in results:\n",
    "            print(result)\n",
    "            print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Async operations error: {e}\")\n",
    "\n",
    "# Run the async demonstration\n",
    "await demonstrate_async_operations()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Complete Tutorial\n",
    "\n",
    "Run all demonstrations in sequence to see the full capabilities of Agno with AgentOps tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to run all Agno demonstrations.\"\"\"\n",
    "    print(\"Starting Comprehensive Agno Tutorial with AgentOps\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Check environment\n",
    "    if not check_environment():\n",
    "        return\n",
    "\n",
    "    # Run all demonstrations\n",
    "    print(\"\\nRunning all Agno demonstrations...\")\n",
    "\n",
    "    # Research teams\n",
    "    try:\n",
    "        demonstrate_research_team()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping research team demo due to: {e}\")\n",
    "\n",
    "    # Basic functionality\n",
    "    demonstrate_basic_agents()\n",
    "\n",
    "    # Tool integration\n",
    "    try:\n",
    "        demonstrate_tool_integration()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping tool integration demo due to: {e}\")\n",
    "\n",
    "    # Workflows\n",
    "    try:\n",
    "        demonstrate_workflows()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping workflow demo due to: {e}\")\n",
    "\n",
    "    # Async operations\n",
    "    try:\n",
    "        await demonstrate_async_operations()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping async demo due to: {e}\")\n",
    "\n",
    "    print(\"\\nAll Agno demonstrations completed!\")\n",
    "    print(\"Check your AgentOps dashboard for detailed traces and metrics.\")\n",
    "\n",
    "# Uncomment the line below to run the complete tutorial\n",
    "# await main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
