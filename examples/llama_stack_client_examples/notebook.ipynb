{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama Stack Client Examples\n",
    "Use the llama_stack_client library to interact with a Llama Stack server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m venv .venv\n",
    "source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-stack-client in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (0.0.56)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (4.6.2.post1)\n",
      "Requirement already satisfied: click in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (0.27.2)\n",
      "Requirement already satisfied: pandas in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (2.2.3)\n",
      "Requirement already satisfied: prompt-toolkit in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (3.0.48)\n",
      "Requirement already satisfied: pyaml in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (24.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (2.10.1)\n",
      "Requirement already satisfied: rich in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (13.9.4)\n",
      "Requirement already satisfied: sniffio in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->llama-stack-client) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama-stack-client) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->llama-stack-client) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama-stack-client) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama-stack-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->llama-stack-client) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client) (2024.2)\n",
      "Requirement already satisfied: wcwidth in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from prompt-toolkit->llama-stack-client) (0.2.13)\n",
      "Requirement already satisfied: PyYAML in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pyaml->llama-stack-client) (6.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from rich->llama-stack-client) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from rich->llama-stack-client) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack-client) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-stack in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (0.0.56)\n",
      "Requirement already satisfied: blobfile in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (3.0.0)\n",
      "Requirement already satisfied: fire in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (0.7.0)\n",
      "Requirement already satisfied: httpx in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (0.26.3)\n",
      "Requirement already satisfied: llama-models>=0.0.56 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (0.0.56)\n",
      "Requirement already satisfied: llama-stack-client>=0.0.56 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (0.0.56)\n",
      "Requirement already satisfied: prompt-toolkit in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (3.0.48)\n",
      "Requirement already satisfied: python-dotenv in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (1.0.1)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (2.10.1)\n",
      "Requirement already satisfied: requests in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (2.32.3)\n",
      "Requirement already satisfied: rich in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (13.9.4)\n",
      "Requirement already satisfied: setuptools in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (75.6.0)\n",
      "Requirement already satisfied: termcolor in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack) (2.5.0)\n",
      "Requirement already satisfied: PyYAML in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-models>=0.0.56->llama-stack) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-models>=0.0.56->llama-stack) (3.1.4)\n",
      "Requirement already satisfied: tiktoken in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-models>=0.0.56->llama-stack) (0.8.0)\n",
      "Requirement already satisfied: Pillow in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-models>=0.0.56->llama-stack) (11.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.6.2.post1)\n",
      "Requirement already satisfied: click in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.9.0)\n",
      "Requirement already satisfied: pandas in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (2.2.3)\n",
      "Requirement already satisfied: pyaml in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (24.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.12.2)\n",
      "Requirement already satisfied: certifi in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpx->llama-stack) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpx->llama-stack) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpx->llama-stack) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-stack) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic>=2->llama-stack) (2.27.1)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from blobfile->llama-stack) (3.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from blobfile->llama-stack) (2.2.3)\n",
      "Requirement already satisfied: lxml>=4.9 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from blobfile->llama-stack) (5.3.0)\n",
      "Requirement already satisfied: filelock>=3.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from blobfile->llama-stack) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from huggingface-hub->llama-stack) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from huggingface-hub->llama-stack) (23.2)\n",
      "Requirement already satisfied: wcwidth in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from requests->llama-stack) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from rich->llama-stack) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from rich->llama-stack) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from jinja2->llama-models>=0.0.56->llama-stack) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from tiktoken->llama-models>=0.0.56->llama-stack) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.0.56->llama-stack) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: agentops in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (0.3.18)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from agentops) (2.32.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from agentops) (5.9.8)\n",
      "Requirement already satisfied: packaging==23.2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from agentops) (23.2)\n",
      "Requirement already satisfied: termcolor>=2.3.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from agentops) (2.5.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.3 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from agentops) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: fastapi in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (0.115.5)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from fastapi) (0.41.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from fastapi) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.6.2.post1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/a/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U llama-stack-client\n",
    "%pip install -U llama-stack\n",
    "%pip install -U agentops\n",
    "%pip install -U python-dotenv\n",
    "%pip install -U fastapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.inference.event_logger import EventLogger\n",
    "from llama_stack_client.types import UserMessage\n",
    "from llama_stack_client.types.agent_create_params import AgentConfig\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import agentops\n",
    "\n",
    "load_dotenv()\n",
    "AGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\") or \"<your_agentops_key>\"\n",
    "\n",
    "# agentops.init(AGENTOPS_API_KEY, default_tags=[\"llama-stack-client-example\"], auto_start_session=False)\n",
    "\n",
    "host = \"0.0.0.0\" # LLAMA_STACK_HOST\n",
    "port = 5001 # LLAMA_STACK_PORT\n",
    "\n",
    "full_host = f\"http://{host}:{port}\"\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=f\"{full_host}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=5f22f2fd-2561-4b8d-8d8c-1ae875d8075c\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'detail': 'Internal server error: An unexpected error occurred.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m agentops\u001b[38;5;241m.\u001b[39mstart_session()\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite me a 3 word poem about the moon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-3.2-1B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m agentops\u001b[38;5;241m.\u001b[39mend_session(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/agentops/llms/llama_stack_client.py:207\u001b[0m, in \u001b[0;36mLlamaStackClientProvider._override_complete.<locals>.patched_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 207\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_response(result, kwargs, init_timestamp, session\u001b[38;5;241m=\u001b[39msession)\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/resources/inference.py:217\u001b[0m, in \u001b[0;36mInferenceResource.chat_completion\u001b[0;34m(self, messages, model_id, logprobs, response_format, sampling_params, stream, tool_choice, tool_prompt_format, tools, x_llama_stack_provider_data, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/event-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    211\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstrip_not_given({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-LlamaStack-ProviderData\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_llama_stack_provider_data}),\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    214\u001b[0m }\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    216\u001b[0m     InferenceChatCompletionResponse,\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/alpha/inference/chat-completion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_prompt_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_prompt_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43minference_chat_completion_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceChatCompletionParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInferenceChatCompletionResponse\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Union types cannot be passed in as arguments in the type system\u001b[39;49;00m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mInferenceChatCompletionResponse\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1251\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1260\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1261\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1262\u001b[0m     )\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/projects/11_2024/agentops/venv/lib/python3.12/site-packages/llama_stack_client/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'detail': 'Internal server error: An unexpected error occurred.'}"
     ]
    }
   ],
   "source": [
    "agentops.start_session()\n",
    "response = client.inference.chat_completion(\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            content=\"write me a 3 word poem about the moon\",\n",
    "            role=\"user\",\n",
    "        ),\n",
    "    ],\n",
    "    model_id=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(f\"> Response: {response}\")\n",
    "agentops.end_session(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion with Streaming Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=9a70187c-87c5-4e7b-bb63-68e303df041e\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mAssistant> \u001b[0m\u001b[33mHere\u001b[0m\u001b[33m is\u001b[0m\u001b[33m a\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m-word\u001b[0m\u001b[33m poem\u001b[0m\u001b[33m about\u001b[0m\u001b[33m the\u001b[0m\u001b[33m moon\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m\"L\u001b[0m\u001b[33munar\u001b[0m\u001b[33m Gentle\u001b[0m\u001b[33m Glow\u001b[0m\u001b[33m\"\u001b[0m\u001b[97m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Session Stats - \u001b[1mDuration:\u001b[0m 2.1s | \u001b[1mCost:\u001b[0m $0.00 | \u001b[1mLLMs:\u001b[0m 1 | \u001b[1mTools:\u001b[0m 0 | \u001b[1mActions:\u001b[0m 0 | \u001b[1mErrors:\u001b[0m 0\n",
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=9a70187c-87c5-4e7b-bb63-68e303df041e\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agentops.start_session()\n",
    "response = client.inference.chat_completion(\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            content=\"hello world, write me a 3 word poem about the moon\",\n",
    "            role=\"user\",\n",
    "        ),\n",
    "    ],\n",
    "    model_id=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "async for log in EventLogger().log(response):\n",
    "    log.print()\n",
    "\n",
    "agentops.end_session(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_!_!_ LlamaStackClientProvider _!_!_\n",
      "_!_!_ override _!_!_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=cd9b9c7f-4335-49f8-ae8a-71a625f0eb06\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No available shields. Disable safety.\n",
      "Using model: meta-llama/Llama-3.2-1B-Instruct\n",
      "response=<async_generator object LlamaStackClientProvider.handle_response.<locals>.async_generator at 0x10ee067a0>\n",
      "response=<async_generator object LlamaStackClientProvider.handle_response.<locals>.async_generator at 0x10ee70900>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Session Stats - \u001b[1mDuration:\u001b[0m 0.8s | \u001b[1mCost:\u001b[0m $0.00 | \u001b[1mLLMs:\u001b[0m 0 | \u001b[1mTools:\u001b[0m 0 | \u001b[1mActions:\u001b[0m 0 | \u001b[1mErrors:\u001b[0m 0\n",
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=cd9b9c7f-4335-49f8-ae8a-71a625f0eb06\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client.types.agent_create_params import AgentConfig\n",
    "\n",
    "agentops.init(AGENTOPS_API_KEY, default_tags=[\"llama-stack-client-example\"], auto_start_session=False)\n",
    "\n",
    "# Apply nest_asyncio to handle nested event loops\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "LLAMA_STACK_PORT = 5001\n",
    "\n",
    "# Replace with actual API keys for functionality\n",
    "os.environ[\"BRAVE_SEARCH_API_KEY\"] = \"your-brave-search-api-key\"\n",
    "\n",
    "async def agent_test():\n",
    "    client = LlamaStackClient(\n",
    "        base_url=f\"http://0.0.0.0:{LLAMA_STACK_PORT}\",\n",
    "    )\n",
    "\n",
    "    available_shields = [shield.identifier for shield in client.shields.list()]\n",
    "    if not available_shields:\n",
    "        print(\"No available shields. Disable safety.\")\n",
    "    else:\n",
    "        print(f\"Available shields found: {available_shields}\")\n",
    "    available_models = [model.identifier for model in client.models.list()]\n",
    "    if not available_models:\n",
    "        raise ValueError(\"No available models\")\n",
    "    else:\n",
    "        selected_model = available_models[0]\n",
    "        print(f\"Using model: {selected_model}\")\n",
    "\n",
    "    agent_config = AgentConfig(\n",
    "        model=selected_model,\n",
    "        instructions=\"You are a helpful assistant. Just say hello as a greeting.\",\n",
    "        sampling_params={\n",
    "            \"strategy\": \"greedy\",\n",
    "            \"temperature\": 1.0,\n",
    "            \"top_p\": 0.9,\n",
    "        },\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"brave_search\",\n",
    "                \"engine\": \"brave\",\n",
    "                \"api_key\": os.getenv(\"BRAVE_SEARCH_API_KEY\"),\n",
    "            }\n",
    "        ],\n",
    "        tool_choice=\"auto\",\n",
    "        tool_prompt_format=\"json\",\n",
    "        input_shields=available_shields if available_shields else [],\n",
    "        output_shields=available_shields if available_shields else [],\n",
    "        enable_session_persistence=False,\n",
    "    )\n",
    "    agent = Agent(client, agent_config)\n",
    "    user_prompts = [\n",
    "        \"Hello\",\n",
    "        \"Which players played in the winning team of the NBA western conference semifinals of 2014, please use tools\",\n",
    "    ]\n",
    "\n",
    "    session_id = agent.create_session(\"test-session\")\n",
    "\n",
    "    for prompt in user_prompts:\n",
    "        response = agent.create_turn(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            session_id=session_id,\n",
    "        )\n",
    "\n",
    "        print(f\"{response=}\")\n",
    "\n",
    "        # async for log in EventLogger().log(response):\n",
    "        #     log.print()\n",
    "\n",
    "agentops.start_session()\n",
    "\n",
    "await agent_test()\n",
    "\n",
    "agentops.end_session(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
