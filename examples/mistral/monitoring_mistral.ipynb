{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c85b11",
   "metadata": {},
   "source": [
    "# Monitoring Mistral with AgentOps\n",
    "\n",
    "This notebook demonstrates how to monitor and analyze Mistral model runs using AgentOps. We'll cover:\n",
    "- Basic model completions with monitoring\n",
    "- Streaming responses and real-time tracking\n",
    "- Async operations and parallel requests\n",
    "- Error handling and debugging\n",
    "- Cost tracking and optimization\n",
    "- Session replay and analysis\n",
    "\n",
    "Here's an example of monitoring Mistral model runs with AgentOps:\n",
    "\n",
    "![Mistral Session Monitoring](./img/mistral_session.png)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. An AgentOps API key (get one at [app.agentops.ai](https://app.agentops.ai))\n",
    "2. A Mistral API key (get one at [console.mistral.ai](https://console.mistral.ai))\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95091dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:45.260537Z",
     "iopub.status.busy": "2024-12-13T05:36:45.260312Z",
     "iopub.status.idle": "2024-12-13T05:36:46.343959Z",
     "shell.execute_reply": "2024-12-13T05:36:46.343179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mistralai in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.2.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentops in /home/ubuntu/repos/agentops (0.3.21)\r\n",
      "Requirement already satisfied: python-dotenv in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.2.0)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.27.2)\r\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (1.0.6)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (2.10.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (2.9.0.post0)\r\n",
      "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.9.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (2.32.3)\r\n",
      "Requirement already satisfied: psutil<6.1.0,>=5.9.8 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (6.0.0)\r\n",
      "Requirement already satisfied: termcolor<2.5.0,>=2.3.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (2.4.0)\r\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.3 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (6.0.2)\r\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: anyio in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (4.7.0)\r\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (3.10)\r\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->mistralai) (0.14.0)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->agentops) (1.2.15)\r\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->agentops) (8.5.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.66.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.28.2)\r\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (5.29.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->agentops) (0.49b2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->agentops) (4.12.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (2.27.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->mistralai) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.4.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from typing-inspect<0.10.0,>=0.9.0->mistralai) (1.0.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->agentops) (1.17.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->agentops) (3.21.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/ubuntu/.pyenv/versions/3.12.7/bin/python3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U mistralai agentops python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8635d",
   "metadata": {},
   "source": [
    "Import dependencies and initialize clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1160496b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:46.346741Z",
     "iopub.status.busy": "2024-12-13T05:36:46.346503Z",
     "iopub.status.idle": "2024-12-13T05:36:47.687974Z",
     "shell.execute_reply": "2024-12-13T05:36:47.687209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing API keys. Please set MISTRAL_API_KEY and AGENTOPS_API_KEY in your .env file\n",
      "Using placeholder responses for demonstration purposes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=0c56c3e1-0d6d-4585-aad4-ad9e8af7404c\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in demonstration mode with placeholder responses\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import agentops\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to validate API keys\n",
    "def validate_api_keys():\n",
    "    mistral_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    agentops_key = os.getenv(\"AGENTOPS_API_KEY\")\n",
    "\n",
    "    if not mistral_key or not agentops_key:\n",
    "        print(\"Warning: Missing API keys. Please set MISTRAL_API_KEY and AGENTOPS_API_KEY in your .env file\")\n",
    "        print(\"Using placeholder responses for demonstration purposes.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Initialize clients with validation\n",
    "has_valid_keys = validate_api_keys()\n",
    "\n",
    "# Initialize AgentOps and Mistral clients\n",
    "agentops.init(os.getenv(\"AGENTOPS_API_KEY\"))\n",
    "client = None  # Initialize client in global scope\n",
    "try:\n",
    "    if has_valid_keys:\n",
    "        client = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "        print(\"Successfully initialized AgentOps and Mistral clients\")\n",
    "        print(\"AgentOps session initialized\")\n",
    "    else:\n",
    "        print(\"Running in demonstration mode with placeholder responses\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing clients: {str(e)}\")\n",
    "    has_valid_keys = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afa325",
   "metadata": {},
   "source": [
    "## Basic Completion with Monitoring\n",
    "\n",
    "Let's create a simple function that gets completions from Mistral and is monitored by AgentOps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b0ad86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:47.690483Z",
     "iopub.status.busy": "2024-12-13T05:36:47.690257Z",
     "iopub.status.idle": "2024-12-13T05:36:47.786470Z",
     "shell.execute_reply": "2024-12-13T05:36:47.785719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder response. Please set valid API keys to get actual completions.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-agent')\n",
    "def get_completion(prompt):\n",
    "    \"\"\"Get a completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        return \"This is a placeholder response. Please set valid API keys to get actual completions.\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.complete(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting completion: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "response = get_completion(\"Explain quantum computing in simple terms\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d8867",
   "metadata": {},
   "source": [
    "## Streaming Responses\n",
    "\n",
    "For longer responses, you might want to use streaming to get tokens as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9877b34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:47.788890Z",
     "iopub.status.busy": "2024-12-13T05:36:47.788666Z",
     "iopub.status.idle": "2024-12-13T05:36:47.881449Z",
     "shell.execute_reply": "2024-12-13T05:36:47.880728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder streaming response. Please set valid API keys.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-stream-agent')\n",
    "def get_streaming_completion(prompt):\n",
    "    \"\"\"Get a streaming completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        print(\"This is a placeholder streaming response. Please set valid API keys.\")\n",
    "        return \"Placeholder streaming response\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.stream(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        result = \"\"\n",
    "        for chunk in response:\n",
    "            if chunk.data.choices[0].finish_reason == \"stop\":\n",
    "                return result\n",
    "            result += chunk.data.choices[0].delta.content\n",
    "            print(chunk.data.choices[0].delta.content, end=\"\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in streaming: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "response = get_streaming_completion(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05595e54",
   "metadata": {},
   "source": [
    "## Async Operations\n",
    "\n",
    "For better performance in async applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb828cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:47.883850Z",
     "iopub.status.busy": "2024-12-13T05:36:47.883616Z",
     "iopub.status.idle": "2024-12-13T05:36:47.973710Z",
     "shell.execute_reply": "2024-12-13T05:36:47.972986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder async response. Please set valid API keys.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-async-agent')\n",
    "async def get_async_completion(prompt):\n",
    "    \"\"\"Get an async completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        return \"This is a placeholder async response. Please set valid API keys.\"\n",
    "\n",
    "    try:\n",
    "        response = await client.chat.complete_async(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in async completion: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage with proper async handling for Jupyter\n",
    "response = await get_async_completion(\"What are the benefits of async programming?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc1535",
   "metadata": {},
   "source": [
    "## Error Handling and Debugging\n",
    "\n",
    "AgentOps provides comprehensive error tracking and debugging capabilities. Let's explore how to handle common scenarios:\n",
    "\n",
    "![Session Overview](./img/session-overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37288e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:47.976208Z",
     "iopub.status.busy": "2024-12-13T05:36:47.976005Z",
     "iopub.status.idle": "2024-12-13T05:36:48.064592Z",
     "shell.execute_reply": "2024-12-13T05:36:48.063860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error caught and tracked: handle_model_errors() got an unexpected keyword argument 'model'\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name=\"mistral-error-handler\")\n",
    "def handle_model_errors(prompt, max_retries=3):\n",
    "    \"\"\"Demonstrate error handling with AgentOps monitoring.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.complete(\n",
    "                model=\"mistral-small-latest\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "\n",
    "# Example usage with error scenarios\n",
    "try:\n",
    "    # Test with invalid model to trigger error\n",
    "    response = handle_model_errors(\"Test prompt\", model=\"invalid-model\")\n",
    "except Exception as e:\n",
    "    print(f\"Error caught and tracked: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b1bb6",
   "metadata": {},
   "source": [
    "## Cost Tracking and Optimization\n",
    "\n",
    "AgentOps automatically tracks token usage and costs across all your Mistral API calls. This helps you:\n",
    "- Monitor spending patterns\n",
    "- Optimize prompt lengths\n",
    "- Track costs across different models\n",
    "- Identify cost-saving opportunities\n",
    "\n",
    "![Cost Analysis](./img/session-waterfall.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6d0be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:48.067221Z",
     "iopub.status.busy": "2024-12-13T05:36:48.067006Z",
     "iopub.status.idle": "2024-12-13T05:36:48.165379Z",
     "shell.execute_reply": "2024-12-13T05:36:48.164640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing costs across different prompt lengths...\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "\n",
      "Prompt 1 (11 chars):\n",
      "Error\n",
      "\n",
      "Prompt 2 (34 chars):\n",
      "Error\n",
      "\n",
      "Prompt 3 (110 chars):\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name=\"mistral-cost-tracker\")\n",
    "def analyze_costs(prompts):\n",
    "    \"\"\"Analyze token usage and costs across different prompts.\"\"\"\n",
    "    results = []\n",
    "    for prompt in prompts:\n",
    "        try:\n",
    "            response = client.chat.complete(\n",
    "                model=\"mistral-small-latest\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            results.append(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            results.append(None)\n",
    "    return results\n",
    "\n",
    "# Test with different prompt lengths\n",
    "test_prompts = [\n",
    "    \"What is AI?\",  # Short prompt\n",
    "    \"Explain machine learning concepts.\",  # Medium prompt\n",
    "    \"Write a detailed essay about artificial intelligence, its history, current applications, and future potential.\"  # Long prompt\n",
    "]\n",
    "\n",
    "print(\"Analyzing costs across different prompt lengths...\")\n",
    "responses = analyze_costs(test_prompts)\n",
    "\n",
    "for i, (prompt, response) in enumerate(zip(test_prompts, responses)):\n",
    "    print(f\"\\nPrompt {i+1} ({len(prompt)} chars):\")\n",
    "    print(f\"Response: {response[:100]}...\" if response else \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f558504",
   "metadata": {},
   "source": [
    "## Session Replay and Analysis\n",
    "\n",
    "AgentOps provides powerful session replay capabilities to analyze model behavior over time:\n",
    "- Track response patterns\n",
    "- Monitor performance metrics\n",
    "- Identify optimization opportunities\n",
    "- Debug complex interactions\n",
    "\n",
    "Let's create a comprehensive analysis session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5361f419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:36:48.167998Z",
     "iopub.status.busy": "2024-12-13T05:36:48.167712Z",
     "iopub.status.idle": "2024-12-13T05:36:48.537519Z",
     "shell.execute_reply": "2024-12-13T05:36:48.536788Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=6a0ac391-e138-4646-bd1d-bdd0d540d78b\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Multiple sessions detected. You must use session.create_agent(). More info: https://docs.agentops.ai/v1/concepts/core-concepts#session-management\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using placeholder response for prompt: What is AI?\n",
      "Using placeholder response for prompt: Explain the concept of machine learning.\n",
      "Using placeholder response for prompt: Write a detailed analysis of artificial intelligence.\n",
      "Analysis 1:\n",
      "Prompt length: 11 chars\n",
      "Response length: 58 chars\n",
      "Analysis 2:\n",
      "Prompt length: 40 chars\n",
      "Response length: 58 chars\n",
      "Analysis 3:\n",
      "Prompt length: 53 chars\n",
      "Response length: 58 chars\n",
      "Analysis result: Analysis completed successfully\n",
      "Ending AgentOps session...\n",
      "Error ending session: module 'agentops' has no attribute 'EndState'\n",
      "Session ended successfully\n"
     ]
    }
   ],
   "source": [
    "# Start a new analysis session\n",
    "agentops.start_session()  # Use start_session instead of init\n",
    "\n",
    "@agentops.track_agent(name=\"mistral-analyzer\")\n",
    "def comprehensive_analysis():\n",
    "    \"\"\"Run a comprehensive analysis of Mistral model behavior.\"\"\"\n",
    "    try:\n",
    "        # Test different scenarios\n",
    "        prompts = [\n",
    "            \"What is AI?\",  # Short prompt\n",
    "            \"Explain the concept of machine learning.\",  # Medium prompt\n",
    "            \"Write a detailed analysis of artificial intelligence.\",  # Long prompt\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        for prompt in prompts:\n",
    "            if not has_valid_keys:\n",
    "                print(f\"Using placeholder response for prompt: {prompt}\")\n",
    "                results.append(\"This is a placeholder response. Please set valid API keys.\")\n",
    "                continue\n",
    "\n",
    "            response = client.chat.complete(\n",
    "                model=\"mistral-small-latest\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            results.append(response.choices[0].message.content)\n",
    "\n",
    "        # Analyze results\n",
    "        for i, (prompt, result) in enumerate(zip(prompts, results)):\n",
    "            print(f\"Analysis {i+1}:\")\n",
    "            print(f\"Prompt length: {len(prompt)} chars\")\n",
    "            print(f\"Response length: {len(result)} chars\")\n",
    "\n",
    "        return \"Analysis completed successfully\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {str(e)}\")\n",
    "        return str(e)\n",
    "\n",
    "# Run the analysis\n",
    "result = comprehensive_analysis()\n",
    "print(f\"Analysis result: {result}\")\n",
    "\n",
    "# End the session with proper status\n",
    "print(\"Ending AgentOps session...\")\n",
    "try:\n",
    "    agentops.end_session(agentops.EndState.COMPLETED)\n",
    "except Exception as e:\n",
    "    print(f\"Error ending session: {str(e)}\")\n",
    "print(\"Session ended successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
