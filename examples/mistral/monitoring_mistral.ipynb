{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f07a0f2",
   "metadata": {},
   "source": [
    "# Monitoring Mistral with AgentOps\n",
    "\n",
    "This notebook demonstrates how to monitor and analyze Mistral model runs using AgentOps. We'll cover:\n",
    "- Basic model completions with monitoring\n",
    "- Streaming responses and real-time tracking\n",
    "- Async operations and parallel requests\n",
    "- Error handling and debugging\n",
    "- Cost tracking and optimization\n",
    "- Session replay and analysis\n",
    "\n",
    "Here's an example of monitoring Mistral model runs with AgentOps:\n",
    "\n",
    "![Mistral Session Monitoring](./img/mistral_session.png)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. An AgentOps API key (get one at [app.agentops.ai](https://app.agentops.ai))\n",
    "2. A Mistral API key (get one at [console.mistral.ai](https://console.mistral.ai))\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87f1d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:38:59.899761Z",
     "iopub.status.busy": "2024-12-13T05:38:59.899532Z",
     "iopub.status.idle": "2024-12-13T05:39:01.009605Z",
     "shell.execute_reply": "2024-12-13T05:39:01.008801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mistralai in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.2.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentops in /home/ubuntu/repos/agentops (0.3.21)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.2.0)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.27.2)\r\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (1.0.6)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (2.10.3)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (2.9.0.post0)\r\n",
      "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from mistralai) (0.9.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (2.32.3)\r\n",
      "Requirement already satisfied: psutil<6.1.0,>=5.9.8 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (6.0.0)\r\n",
      "Requirement already satisfied: termcolor<2.5.0,>=2.3.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (2.4.0)\r\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.3 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (6.0.2)\r\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from agentops) (1.28.2)\r\n",
      "Requirement already satisfied: anyio in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (4.7.0)\r\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (3.10)\r\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->mistralai) (0.14.0)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->agentops) (1.2.15)\r\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->agentops) (8.5.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.66.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.28.2)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (1.28.2)\r\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->agentops) (5.29.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->agentops) (0.49b2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->agentops) (4.12.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (2.27.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->mistralai) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.4.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from typing-inspect<0.10.0,>=0.9.0->mistralai) (1.0.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->agentops) (1.17.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->agentops) (3.21.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/ubuntu/.pyenv/versions/3.12.7/bin/python3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U mistralai agentops python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211da48",
   "metadata": {},
   "source": [
    "Import dependencies and initialize clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406eab6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:01.012351Z",
     "iopub.status.busy": "2024-12-13T05:39:01.012101Z",
     "iopub.status.idle": "2024-12-13T05:39:03.704545Z",
     "shell.execute_reply": "2024-12-13T05:39:03.703650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing API keys. Please set MISTRAL_API_KEY and AGENTOPS_API_KEY in your .env file\n",
      "Using placeholder responses for demonstration purposes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=b422759d-d29a-48fa-b8de-8bd3320a3878\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in demonstration mode with placeholder responses\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import agentops\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to validate API keys\n",
    "def validate_api_keys():\n",
    "    mistral_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    agentops_key = os.getenv(\"AGENTOPS_API_KEY\")\n",
    "\n",
    "    if not mistral_key or not agentops_key:\n",
    "        print(\"Warning: Missing API keys. Please set MISTRAL_API_KEY and AGENTOPS_API_KEY in your .env file\")\n",
    "        print(\"Using placeholder responses for demonstration purposes.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Initialize clients with validation\n",
    "has_valid_keys = validate_api_keys()\n",
    "\n",
    "# Initialize AgentOps and Mistral clients\n",
    "agentops.init(os.getenv(\"AGENTOPS_API_KEY\"))\n",
    "client = None  # Initialize client in global scope\n",
    "try:\n",
    "    if has_valid_keys:\n",
    "        client = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "        print(\"Successfully initialized AgentOps and Mistral clients\")\n",
    "        print(\"AgentOps session initialized\")\n",
    "    else:\n",
    "        print(\"Running in demonstration mode with placeholder responses\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing clients: {str(e)}\")\n",
    "    has_valid_keys = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e4b2c",
   "metadata": {},
   "source": [
    "## Basic Completion with Monitoring\n",
    "\n",
    "Let's create a simple function that gets completions from Mistral and is monitored by AgentOps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6c03fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:03.707145Z",
     "iopub.status.busy": "2024-12-13T05:39:03.706898Z",
     "iopub.status.idle": "2024-12-13T05:39:03.802925Z",
     "shell.execute_reply": "2024-12-13T05:39:03.802075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder response. Please set valid API keys to get actual completions.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-agent')\n",
    "def get_completion(prompt):\n",
    "    \"\"\"Get a completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        return \"This is a placeholder response. Please set valid API keys to get actual completions.\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.complete(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting completion: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "response = get_completion(\"Explain quantum computing in simple terms\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8090521",
   "metadata": {},
   "source": [
    "## Streaming Responses\n",
    "\n",
    "For longer responses, you might want to use streaming to get tokens as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9da9354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:03.805492Z",
     "iopub.status.busy": "2024-12-13T05:39:03.805284Z",
     "iopub.status.idle": "2024-12-13T05:39:03.941413Z",
     "shell.execute_reply": "2024-12-13T05:39:03.940525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder streaming response. Please set valid API keys.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-stream-agent')\n",
    "def get_streaming_completion(prompt):\n",
    "    \"\"\"Get a streaming completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        print(\"This is a placeholder streaming response. Please set valid API keys.\")\n",
    "        return \"Placeholder streaming response\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.stream(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        result = \"\"\n",
    "        for chunk in response:\n",
    "            if chunk.data.choices[0].finish_reason == \"stop\":\n",
    "                return result\n",
    "            result += chunk.data.choices[0].delta.content\n",
    "            print(chunk.data.choices[0].delta.content, end=\"\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in streaming: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "response = get_streaming_completion(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9228431",
   "metadata": {},
   "source": [
    "## Async Operations\n",
    "\n",
    "For better performance in async applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2daff87f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:03.943951Z",
     "iopub.status.busy": "2024-12-13T05:39:03.943730Z",
     "iopub.status.idle": "2024-12-13T05:39:04.048385Z",
     "shell.execute_reply": "2024-12-13T05:39:04.047483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a placeholder async response. Please set valid API keys.\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name='mistral-async-agent')\n",
    "async def get_async_completion(prompt):\n",
    "    \"\"\"Get an async completion from Mistral with monitoring.\"\"\"\n",
    "    if not has_valid_keys:\n",
    "        return \"This is a placeholder async response. Please set valid API keys.\"\n",
    "\n",
    "    try:\n",
    "        response = await client.chat.complete_async(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in async completion: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage with proper async handling for Jupyter\n",
    "response = await get_async_completion(\"What are the benefits of async programming?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d0561",
   "metadata": {},
   "source": [
    "## Error Handling and Debugging\n",
    "\n",
    "AgentOps provides comprehensive error tracking and debugging capabilities. Let's explore how to handle common scenarios:\n",
    "\n",
    "![Session Overview](./img/session-overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810272a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:04.050784Z",
     "iopub.status.busy": "2024-12-13T05:39:04.050571Z",
     "iopub.status.idle": "2024-12-13T05:39:04.151355Z",
     "shell.execute_reply": "2024-12-13T05:39:04.150529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error caught and tracked: handle_model_errors() got an unexpected keyword argument 'model'\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name=\"mistral-error-handler\")\n",
    "def handle_model_errors(prompt, max_retries=3):\n",
    "    \"\"\"Demonstrate error handling with AgentOps monitoring.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.complete(\n",
    "                model=\"mistral-small-latest\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "\n",
    "# Example usage with error scenarios\n",
    "try:\n",
    "    # Test with invalid model to trigger error\n",
    "    response = handle_model_errors(\"Test prompt\", model=\"invalid-model\")\n",
    "except Exception as e:\n",
    "    print(f\"Error caught and tracked: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbec6a",
   "metadata": {},
   "source": [
    "## Cost Tracking and Optimization\n",
    "\n",
    "AgentOps automatically tracks token usage and costs across all your Mistral API calls. This helps you:\n",
    "- Monitor spending patterns\n",
    "- Optimize prompt lengths\n",
    "- Track costs across different models\n",
    "- Identify cost-saving opportunities\n",
    "\n",
    "![Cost Analysis](./img/session-waterfall.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5050013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:04.153858Z",
     "iopub.status.busy": "2024-12-13T05:39:04.153648Z",
     "iopub.status.idle": "2024-12-13T05:39:04.253409Z",
     "shell.execute_reply": "2024-12-13T05:39:04.252519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing costs across different prompt lengths...\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "Error: 'NoneType' object has no attribute 'chat'\n",
      "\n",
      "Prompt 1 (11 chars):\n",
      "Error\n",
      "\n",
      "Prompt 2 (34 chars):\n",
      "Error\n",
      "\n",
      "Prompt 3 (110 chars):\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "@agentops.track_agent(name=\"mistral-cost-tracker\")\n",
    "def analyze_costs(prompts):\n",
    "    \"\"\"Analyze token usage and costs across different prompts.\"\"\"\n",
    "    results = []\n",
    "    for prompt in prompts:\n",
    "        try:\n",
    "            response = client.chat.complete(\n",
    "                model=\"mistral-small-latest\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            results.append(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            results.append(None)\n",
    "    return results\n",
    "\n",
    "# Test with different prompt lengths\n",
    "test_prompts = [\n",
    "    \"What is AI?\",  # Short prompt\n",
    "    \"Explain machine learning concepts.\",  # Medium prompt\n",
    "    \"Write a detailed essay about artificial intelligence, its history, current applications, and future potential.\"  # Long prompt\n",
    "]\n",
    "\n",
    "print(\"Analyzing costs across different prompt lengths...\")\n",
    "responses = analyze_costs(test_prompts)\n",
    "\n",
    "for i, (prompt, response) in enumerate(zip(test_prompts, responses)):\n",
    "    print(f\"\\nPrompt {i+1} ({len(prompt)} chars):\")\n",
    "    print(f\"Response: {response[:100]}...\" if response else \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7619da6",
   "metadata": {},
   "source": [
    "## Session Replay and Analysis\n",
    "\n",
    "AgentOps provides powerful session replay capabilities to analyze model behavior over time:\n",
    "- Track response patterns\n",
    "- Monitor performance metrics\n",
    "- Identify optimization opportunities\n",
    "- Debug complex interactions\n",
    "\n",
    "Let's create a comprehensive analysis session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90198c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T05:39:04.256042Z",
     "iopub.status.busy": "2024-12-13T05:39:04.255781Z",
     "iopub.status.idle": "2024-12-13T05:39:04.761543Z",
     "shell.execute_reply": "2024-12-13T05:39:04.760564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=62561fd6-d93e-4cd9-aec1-9619a98498c2\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Session.create_agent() missing 1 required positional argument: 'agent_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcomprehensive_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# End the session with proper status\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mcomprehensive_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a comprehensive analysis of Mistral model behavior.\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create an agent for this analysis\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-analyzer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Test different scenarios\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is AI?\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Short prompt\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain the concept of machine learning.\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Medium prompt\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a detailed analysis of artificial intelligence.\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Long prompt\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     ]\n",
      "\u001b[0;31mTypeError\u001b[0m: Session.create_agent() missing 1 required positional argument: 'agent_id'"
     ]
    }
   ],
   "source": [
    "# Start a new analysis session\n",
    "from agentops.session import EndState  # Import EndState from correct module\n",
    "session = agentops.start_session()\n",
    "\n",
    "def comprehensive_analysis():\n",
    "    \"\"\"Run a comprehensive analysis of Mistral model behavior.\"\"\"\n",
    "    # Create an agent for this analysis\n",
    "    agent = session.create_agent(name=\"mistral-analyzer\")\n",
    "\n",
    "    try:\n",
    "        # Test different scenarios\n",
    "        prompts = [\n",
    "            \"What is AI?\",  # Short prompt\n",
    "            \"Explain the concept of machine learning.\",  # Medium prompt\n",
    "            \"Write a detailed analysis of artificial intelligence.\",  # Long prompt\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        for prompt in prompts:\n",
    "            if not has_valid_keys:\n",
    "                print(f\"Using placeholder response for prompt: {prompt}\")\n",
    "                results.append(\"This is a placeholder response. Please set valid API keys.\")\n",
    "                continue\n",
    "\n",
    "            with agent:  # Use context manager for proper tracking\n",
    "                try:\n",
    "                    response = client.chat.complete(\n",
    "                        model=\"mistral-small-latest\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                    )\n",
    "                    results.append(response.choices[0].message.content)\n",
    "                except AttributeError:\n",
    "                    print(\"Client not initialized. Using placeholder response.\")\n",
    "                    results.append(\"This is a placeholder response. Please set valid API keys.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during completion: {str(e)}\")\n",
    "                    results.append(f\"Error: {str(e)}\")\n",
    "\n",
    "        # Analyze results\n",
    "        for i, (prompt, result) in enumerate(zip(prompts, results)):\n",
    "            print(f\"Analysis {i+1}:\")\n",
    "            print(f\"Prompt length: {len(prompt)} chars\")\n",
    "            print(f\"Response length: {len(result)} chars\")\n",
    "\n",
    "        return \"Analysis completed successfully\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {str(e)}\")\n",
    "        return str(e)\n",
    "\n",
    "# Run the analysis\n",
    "result = comprehensive_analysis()\n",
    "print(f\"Analysis result: {result}\")\n",
    "\n",
    "# End the session with proper status\n",
    "print(\"Ending AgentOps session...\")\n",
    "try:\n",
    "    session.end(EndState.COMPLETED)  # Use imported EndState\n",
    "except Exception as e:\n",
    "    print(f\"Error ending session: {str(e)}\")\n",
    "print(\"Session ended successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
