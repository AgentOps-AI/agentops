{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69829505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import logging\n",
    "import asyncio\n",
    "import agentops\n",
    "from fireworks.client import Fireworks\n",
    "from agentops.llms.providers.fireworks import FireworksProvider\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for API keys\n",
    "if \"FIREWORKS_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"FIREWORKS_API_KEY environment variable is not set\")\n",
    "if \"AGENTOPS_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"AGENTOPS_API_KEY environment variable is not set\")\n",
    "\n",
    "# Initialize AgentOps\n",
    "print(\"\\nInitializing AgentOps...\")\n",
    "agentops.init(os.getenv(\"AGENTOPS_API_KEY\"), default_tags=[\"Fireworks Example\"])\n",
    "\n",
    "# Initialize Fireworks client and provider\n",
    "print(\"\\nInitializing Fireworks client and provider...\")\n",
    "client = Fireworks()\n",
    "provider = FireworksProvider(client)\n",
    "provider.override()\n",
    "print(\"Fireworks client and provider initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6785170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test messages for story generation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a creative storyteller.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a short story about a cyber-warrior trapped in the imperial era.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test synchronous non-streaming completion\n",
    "print(\"1. Generating story with synchronous non-streaming completion...\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "    messages=messages\n",
    ")\n",
    "print(\"\\nSync Non-streaming Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\nEvent recorded for sync non-streaming completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test asynchronous non-streaming completion\n",
    "print(\"2. Generating story with asynchronous non-streaming completion...\")\n",
    "\n",
    "async def async_completion():\n",
    "    response = await client.chat.completions.acreate(\n",
    "        model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "        messages=messages\n",
    "    )\n",
    "    print(\"\\nAsync Non-streaming Response:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\nEvent recorded for async non-streaming completion\")\n",
    "\n",
    "await async_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Test synchronous streaming completion\n",
    "print(\"3. Generating story with synchronous streaming...\")\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "print(\"\\nSync Streaming Response:\")\n",
    "for chunk in stream:\n",
    "    if hasattr(chunk, \"choices\") and chunk.choices and hasattr(chunk.choices[0].delta, \"content\"):\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "print(\"\\nEvent recorded for sync streaming completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Test asynchronous streaming completion\n",
    "print(\"4. Generating story with asynchronous streaming...\")\n",
    "\n",
    "async def async_streaming():\n",
    "    try:\n",
    "        stream = await client.chat.completions.acreate(\n",
    "            model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        print(\"\\nAsync Streaming Response:\")\n",
    "        async for chunk in stream:\n",
    "            if hasattr(chunk, \"choices\") and chunk.choices and hasattr(chunk.choices[0].delta, \"content\"):\n",
    "                content = chunk.choices[0].delta.content\n",
    "                if content:\n",
    "                    print(content, end=\"\", flush=True)\n",
    "        print(\"\\nEvent recorded for async streaming completion\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in async streaming: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "await async_streaming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End session and show detailed stats\n",
    "print(\"\\nEnding session and showing statistics...\")\n",
    "session_stats = agentops.end_session(\"Success\")\n",
    "print(\"\\nSession Statistics:\")\n",
    "print(f\"LLM Events: {session_stats.get('llm_events', 0)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
