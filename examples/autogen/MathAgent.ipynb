{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6538d8-2a5d-4a99-b2c1-7130963e4f7b",
   "metadata": {},
   "source": [
    "# Microsoft Autogen Tool Example\n",
    "\n",
    "AgentOps automatically configures itself when it's initialized meaning your agent run data will be tracked and logged to your AgentOps account right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083244fa",
   "metadata": {},
   "source": [
    "First let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8104ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U autogen-agentchat\n",
    "%pip install -U \"autogen-ext[openai]\"\n",
    "%pip install -U agentops\n",
    "%pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44e459",
   "metadata": {},
   "source": [
    "Then import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.error import (\n",
    "    StdinNotImplementedError,\n",
    ")\n",
    "\n",
    "import agentops\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.messages import TextMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8bd70",
   "metadata": {},
   "source": [
    "Next, we'll set our API keys. There are several ways to do this, the code below is just the most foolproof way for the purposes of this notebook. It accounts for both users who use environment variables and those who just want to set the API Key here in this notebook.\n",
    "\n",
    "[Get an AgentOps API key](https://agentops.ai/settings/projects)\n",
    "\n",
    "1. Create an environment variable in a .env file or other method. By default, the AgentOps `init()` function will look for an environment variable named `AGENTOPS_API_KEY`. Or...\n",
    "\n",
    "2. Replace `<your_agentops_key>` below and pass in the optional `api_key` parameter to the AgentOps `init(api_key=...)` function. Remember not to commit your API key to a public repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"AGENTOPS_API_KEY\"] = os.getenv(\"AGENTOPS_API_KEY\", \"your_api_key_here\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f2339-7b99-4cf1-9232-c24faba49c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) ðŸ–‡ AgentOps: [opentelemetry.sdk.metrics._internal.export] Exception while exporting metrics\n"
     ]
    }
   ],
   "source": [
    "agentops.init(auto_start_session=False)\n",
    "tracer = agentops.start_trace(trace_name=\"Microsoft Autogen Tool Example\", tags=[\"autogen-tool\", \"microsoft-autogen\", \"agentops-example\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858f0f6-9aca-4cdb-a514-9fbf7e353d50",
   "metadata": {},
   "source": [
    "AG2 will now start automatically tracking\n",
    "\n",
    "* LLM prompts and completions\n",
    "* Token usage and costs\n",
    "* Agent names and actions\n",
    "* Correspondence between agents\n",
    "* Tool usage\n",
    "* Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc592637",
   "metadata": {},
   "source": [
    "# Tool Example\n",
    "AgentOps tracks when AG2 agents use tools. You can find more information on this example in [tool-use.ipynb](https://docs.ag2.ai/docs/tutorial/tool-use#tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dfe37-85e0-4035-a314-3459c6e378c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and API key\n",
    "model_name = \"gpt-4-turbo\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create the model client\n",
    "model_client = OpenAIChatCompletionClient(model=model_name, api_key=api_key, seed=42, temperature=0)\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")\n",
    "\n",
    "async def main():\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"Assistant\",\n",
    "        system_message=\"You are a helpful AI assistant. You can help with simple calculations. Return 'TERMINATE' when the task is done.\",\n",
    "        model_client=model_client,\n",
    "        tools=[calculator],\n",
    "        reflect_on_tool_use=True\n",
    "    )\n",
    "\n",
    "    initial_task_message = \"What is (1423 - 123) / 3 + (32 + 23) * 5?\"\n",
    "    print(f\"User Task: {initial_task_message}\")\n",
    "\n",
    "    try:\n",
    "        from autogen_core import CancellationToken\n",
    "        \n",
    "        response = await assistant.on_messages(\n",
    "            [TextMessage(content=initial_task_message, source=\"user\")],\n",
    "            CancellationToken()\n",
    "        )\n",
    "        \n",
    "        final_response_message = response.chat_message\n",
    "        if final_response_message:\n",
    "             print(f\"Assistant: {final_response_message.to_text()}\")\n",
    "        else:\n",
    "            print(\"Assistant did not provide a final message.\")\n",
    "\n",
    "        agentops.end_trace(tracer, end_state=\"Success\")\n",
    "\n",
    "    except StdinNotImplementedError:\n",
    "        print(\"StdinNotImplementedError: This typically happens in non-interactive environments.\")\n",
    "        agentops.end_trace(tracer, end_state=\"Indeterminate\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        agentops.end_trace(tracer, end_state=\"Error\")\n",
    "    finally:\n",
    "        await model_client.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "\n",
    "    if loop and loop.is_running():\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        asyncio.run(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b0305-1247-489e-b1b0-829127af76d3",
   "metadata": {},
   "source": [
    "You can see your run in action at [app.agentops.ai](app.agentops.ai). In this example, the AgentOps dashboard will show:\n",
    "\n",
    "* Agents talking to each other\n",
    "* Each use of the `calculator` tool\n",
    "* Each call to OpenAI for LLM use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentops (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
