{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multiple Concurrent Sessions\n",
    "This example will show you how to run multiple sessions concurrently, assigning LLM cals to a specific session."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0fe80a38dec2f7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import agentops\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from agentops import ActionEvent\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, of course, lets init AgentOps. We're going to bypass creating a session automatically for the sake of showing it below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da9cf64965c86ee9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agentops.init(auto_start_session=False)\n",
    "openai = OpenAI()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:47.585590Z",
     "start_time": "2024-07-12T21:57:47.571481Z"
    }
   },
   "id": "39af2cd027ce268",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets create two sessions, each with an identifiable tag."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9501d298aec35510"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001B[34m\u001B[34mSession Replay: https://app.agentops.ai/drilldown?session_id=e8d61d17-270d-441a-a724-28ef0090d0a8\u001B[0m\u001B[0m\n",
      "ðŸ–‡ AgentOps: \u001B[34m\u001B[34mSession Replay: https://app.agentops.ai/drilldown?session_id=a1f8a4c7-c3fa-41bd-97b8-6eda26dbd1c2\u001B[0m\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id_1: e8d61d17-270d-441a-a724-28ef0090d0a8\n",
      "session_id_2: a1f8a4c7-c3fa-41bd-97b8-6eda26dbd1c2\n"
     ]
    }
   ],
   "source": [
    "session_1 = agentops.start_session(tags=[\"multi-session-test-1\"])\n",
    "session_2 = agentops.start_session(tags=[\"multi-session-test-2\"])\n",
    "\n",
    "print(\"session_id_1: {}\".format(session_1.session_id))\n",
    "print(\"session_id_2: {}\".format(session_2.session_id))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:49.140581Z",
     "start_time": "2024-07-12T21:57:47.585661Z"
    }
   },
   "id": "4f24d06dd29579ff",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LLM Calls\n",
    "Now lets go ahead and make our first OpenAI LLM call. The challenge with having multiple sessions at the same time is that there is no way for AgentOps to know what LLM call is intended to pertain to what active session. This means we need to do a little extra work in one of two ways."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38f373b7a8878a68"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hello\"}]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:49.140968Z",
     "start_time": "2024-07-12T21:57:49.138115Z"
    }
   },
   "id": "8a2d65f5fcdb137",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Patching Function\n",
    "This method involves wrapping the LLM call withing a function on session. It can look a little counter-intuitive, but it easily tells us what session the call belongs to."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1859e37b65669b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# option 1: use session.patch\n",
    "response = session_1.patch(openai.chat.completions.create)(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:49.688591Z",
     "start_time": "2024-07-12T21:57:49.143357Z"
    }
   },
   "id": "106a1c899602bd33",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create patched function\n",
    "If you're using the create function multiple times, you can create a new function with the same method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e129661929e8368"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "observed_create = session_1.patch(openai.chat.completions.create)\n",
    "obs_response = observed_create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:50.038932Z",
     "start_time": "2024-07-12T21:57:49.690806Z"
    }
   },
   "id": "be3b866ee04ef767",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keyword Argument\n",
    "Alternatively, you can also pass the session into the LLM function call as a keyword argument. While this method works and is a bit more readable, it is not a \"pythonic\" pattern and can lead to linting errors in the code, as the base function is not expecting a `session` keyword."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec03dbfb7a185d1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# option 2: add session as a keyword argument\n",
    "response2 = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=messages, temperature=0.5, session=session_2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:50.962033Z",
     "start_time": "2024-07-12T21:57:50.042297Z"
    }
   },
   "id": "4ad4c7629509b4be",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recording Events\n",
    "Outside of LLM calls, there are plenty of other events that we want to track. You can learn more about these events [here](https://docs.agentops.ai/v1/concepts/events).\n",
    "\n",
    "Recording these events on a session is as simple as `session.record(...)`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6de84850aa2e135"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "session_1.record(ActionEvent(action_type=\"test event\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:50.971921Z",
     "start_time": "2024-07-12T21:57:50.962949Z"
    }
   },
   "id": "964e3073bac33223",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's go ahead and end the sessions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43ac0b9b99eab5c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "session_1.end_session(end_state=\"Success\")\n",
    "session_2.end_session(end_state=\"Success\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3050abcb72421b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you look in the AgentOps dashboard for these sessions, you will see two unique sessions, both with one LLM Event each, one with an Action Event as well."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53ea2b8dfee6270a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dbc7483434f8c147"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
