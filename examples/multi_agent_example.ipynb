{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e266428cefc683",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Multi-Agent Support\n",
    "<img src=\"https://github.com/AgentOps-AI/agentops/blob/b4aac2d4b9fb16d6aa0a25aa9018210a94f1bef2/docs/logo/multion_integration.png?raw=true\" width=\"250px\" style=\"max-width: 100%; height: auto;\"/>\n",
    "    \n",
    "AgentOps supports tracking multiple agents in a single session. With AgentOps, agent actions as well as MultiOn browse events will get tracked. MultiOn browse events automatically trace screenshots as well.\n",
    "\n",
    "This is an example implementation of tracking events from two separate agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c566fac57d3b6ce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import agentops\n",
    "from agentops.agent import track_agent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c52496c04693",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', \"<your_openai_key>\")\n",
    "AGENTOPS_API_KEY = os.getenv('AGENTOPS_API_KEY', \"<your_agentops_key>\")\n",
    "logging.basicConfig(level=logging.DEBUG) # this will let us see that calls are assigned to an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af062552554d60ce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "agentops.init(AGENTOPS_API_KEY)\n",
    "openai_client = OpenAI(api_key = OPENAI_API_KEY )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d212546aaf1f82",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now lets create a few agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3cc26ce3ec3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@track_agent(name='qa')\n",
    "class QaAgent:\n",
    "    def completion(self, prompt: str):\n",
    "        res = openai_client.chat.completions.create(model='gpt-3.5-turbo', \n",
    "                                                    messages=[{\"role\": \"system\", \n",
    "                                                               \"content\": \"You are a qa engineer and only output python code, no markdown tags.\"},\n",
    "                                                              {\"role\": \"user\", \"content\": prompt}],\n",
    "                                                    temperature=0.5)\n",
    "        return res.choices[0].message.content\n",
    "        \n",
    "@track_agent(name='engineer')\n",
    "class EngineerAgent:\n",
    "    def completion(self, prompt: str):\n",
    "        res = openai_client.chat.completions.create(model='gpt-3.5-turbo',\n",
    "                                                    messages=[{\"role\": \"system\", \n",
    "                                                               \"content\": \"You are a software engineer and only output python code, no markdown tags.\"},\n",
    "                                                              {\"role\": \"user\", \"content\": prompt}], \n",
    "                                                    temperature=0.5)\n",
    "        return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b75d65de738522",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "qa = QaAgent()\n",
    "engineer = EngineerAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd3af9206308cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we have our agents and we tagged them with the `@track_agent` decorator. Any LLM calls that go through this class will now be tagged as agent calls in AgentOps.\n",
    "\n",
    "Lets use these agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e76061a626549",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generated_func = engineer.completion(\"Write a python function that accepts two numbers and multiplies them together, then divides by two. No example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b86dac47dceb3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown('```python\\n' + generated_func + '\\n```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9d0d457aee91a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generated_test = qa.completion(\"Write a python unit test that test the following function: \\n \" + generated_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ffcbd2015d422",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown('```python\\n' + generated_test + '\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd312ed049a5511",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Perfect! It generated the code as expected, and in the DEBUG logs, you can see that the calls were made by agents named \"engineer\" and \"qa\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0817a31756397",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Lets verify one more thing! If we make an LLM call outside of the context of a tracked agent, we want to make sure it gets assigned to the Default Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e923cb07fd5f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are not a tracked agent\"},\n",
    "    {\"role\": \"user\", \"content\": \"Say hello\"}]\n",
    ")\n",
    "res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30909020c6a1ada",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "You'll notice that we didn't log an agent name, so the AgentOps backend will assign it to the Default Agent for the session!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
