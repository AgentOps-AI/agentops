{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Watsonx AI Tokenization and Model Details with AgentOps\n",
    "\n",
    "This notebook demonstrates how to use IBM Watsonx AI for tokenization and retrieving model details with AgentOps instrumentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and initialize AgentOps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agentops\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize AgentOps\n",
    "agentops.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize IBM Watsonx AI Credentials\n",
    "\n",
    "To use IBM Watsonx AI, you need to set up your credentials and project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize credentials - replace with your own API key\n",
    "# Best practice: Store API keys in environment variables\n",
    "credentials = Credentials(\n",
    "    url=os.getenv(\"WATSONX_URL\", \"https://eu-de.ml.cloud.ibm.com\"),\n",
    "    api_key=os.getenv(\"WATSONX_API_KEY\", \"your-api-key-here\"),\n",
    ")\n",
    "\n",
    "# Project ID for your IBM Watsonx project\n",
    "project_id = os.getenv(\"WATSONX_PROJECT_ID\", \"your-project-id-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model\n",
    "\n",
    "Let's initialize a model to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ModelInference(\n",
    "    model_id=\"google/flan-ul2\",\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Let's use IBM Watsonx AI to tokenize text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text to tokenize\n",
    "text_to_tokenize = \"Hello, how are you today?\"\n",
    "tokens = model.tokenize(text_to_tokenize)\n",
    "print(f\"Tokenization Result:\\n{tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Longer Text\n",
    "\n",
    "Let's try tokenizing a longer piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longer text to tokenize\n",
    "longer_text = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, \n",
    "as opposed to intelligence displayed by humans or other animals. \n",
    "Example tasks in which this is done include speech recognition, computer vision, \n",
    "translation between languages, and decision-making.\"\"\"\n",
    "\n",
    "tokens = model.tokenize(longer_text)\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Details\n",
    "\n",
    "Let's retrieve and display details about the model we're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model details\n",
    "model_details = model.get_details()\n",
    "print(f\"Model Details:\\n{model_details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a Different Model\n",
    "\n",
    "Let's initialize a different model and get its details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize another model\n",
    "llama_model = ModelInference(\n",
    "    model_id=\"meta-llama/llama-3-3-70b-instruct\",\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "# Get details of the new model\n",
    "llama_model_details = llama_model.get_details()\n",
    "print(f\"Llama Model Details:\\n{llama_model_details}\")\n",
    "\n",
    "# Example text tokenization with the new model\n",
    "example_text = \"Let's see how this model tokenizes text.\"\n",
    "llama_tokens = llama_model.tokenize(example_text)\n",
    "print(f\"\\nTokenization with Llama model:\\n{llama_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Tokenization Between Models\n",
    "\n",
    "Let's compare how different models tokenize the same text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to compare tokenization\n",
    "comparison_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize with first model\n",
    "flan_tokens = model.tokenize(comparison_text)\n",
    "print(f\"FLAN-UL2 tokens: {flan_tokens}\")\n",
    "\n",
    "# Tokenize with second model\n",
    "llama_tokens = llama_model.tokenize(comparison_text)\n",
    "print(f\"\\nLlama tokens: {llama_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Finally, let's close the persistent connection with the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connections\n",
    "model.close_persistent_connection()\n",
    "llama_model.close_persistent_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
