{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6538d8-2a5d-4a99-b2c1-7130963e4f7b",
   "metadata": {},
   "source": [
    "# AG2 Tool Example\n",
    "<img src=\"https://raw.githubusercontent.com/AgentOps-AI/agentops/main/docs/images/external/autogen/autogen-integration.png?raw=true\" width=\"25%\"/>\n",
    "\n",
    "To get started, you'll need to install the AgentOps package and [set an API key](app.agentops.ai).\n",
    "\n",
    "AgentOps automatically configures itself when it's initialized meaning your agent run data will be tracked and logged to your AgentOps account right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083244fa",
   "metadata": {},
   "source": [
    "First let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8104ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pyautogen\n",
    "%pip install -U agentops\n",
    "%pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44e459",
   "metadata": {},
   "source": [
    "Then import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7672f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_67312\\1747695872.py\", line 2, in <module>\n",
      "    from autogen import ConversableAgent, register_function\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\__init__.py\", line 9, in <module>\n",
      "    from .agentchat import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\__init__.py\", line 12, in <module>\n",
      "    from .contrib.swarm_agent import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\contrib\\swarm_agent.py\", line 22, in <module>\n",
      "    from ..groupchat import SELECT_SPEAKER_PROMPT_TEMPLATE, GroupChat, GroupChatManager\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\groupchat.py\", line 19, in <module>\n",
      "    from ..graph_utils import check_graph_validity, invert_disallowed_to_allowed\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\graph_utils.py\", line 15, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py\", line 174, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\ticker.py\", line 143, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Literal\n",
    "from autogen import ConversableAgent, register_function\n",
    "import agentops\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.error import (\n",
    "    StdinNotImplementedError,\n",
    ")  # only needed by AgentOps testing automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8bd70",
   "metadata": {},
   "source": [
    "Next, we'll set our API keys. There are several ways to do this, the code below is just the most foolproof way for the purposes of this notebook. It accounts for both users who use environment variables and those who just want to set the API Key here in this notebook.\n",
    "\n",
    "[Get an AgentOps API key](https://agentops.ai/settings/projects)\n",
    "\n",
    "1. Create an environment variable in a .env file or other method. By default, the AgentOps `init()` function will look for an environment variable named `AGENTOPS_API_KEY`. Or...\n",
    "\n",
    "2. Replace `<your_agentops_key>` below and pass in the optional `api_key` parameter to the AgentOps `init(api_key=...)` function. Remember not to commit your API key to a public repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eeaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or \"<your_openai_key>\"\n",
    "AGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\") or \"<your_agentops_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93f2339-7b99-4cf1-9232-c24faba49c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: Including project_id in resource attributes: fd6006a1-e230-4416-b1c7-f442d195a718\n",
      "(DEBUG) 🖇 AgentOps: Tracing core initialized\n",
      "(DEBUG) 🖇 AgentOps: Instrumented OpenAIInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Instrumented AnthropicInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Instrumented CohereInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.trace] Overriding of current TracerProvider is not allowed\n",
      "(DEBUG) 🖇 AgentOps: Instrumented CrewAIInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Instrumented GroqInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.instrumentor] DependencyConflict: requested: \"haystack-ai >= 2.0.0\" but found: \"haystack-ai 2.11.0rc0\"\n",
      "(DEBUG) 🖇 AgentOps: Instrumented HaystackInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Instrumented MistralAiInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Package ollama not found; skipping instrumentation of OllamaInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: Instrumented AgentsInstrumentor\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] Instrumenting AutoGen\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] Instrumented ConversableAgent.generate_reply\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] Instrumented ConversableAgent.generate_oai_reply\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] Instrumented ConversableAgent.execute_function\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] Failed to instrument GroupChat.run: type object 'GroupChat' has no attribute 'run'\n",
      "(DEBUG) 🖇 AgentOps: [opentelemetry.instrumentation.autogen.instrumentation] AutoGen instrumentation complete\n",
      "(DEBUG) 🖇 AgentOps: Instrumented AutoGenInstrumentor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentOps is now running. You can view your session in the link above\n"
     ]
    }
   ],
   "source": [
    "agentops.init(AGENTOPS_API_KEY, default_tags=[\"autogen-tool-example\"])\n",
    "\n",
    "print(\"AgentOps is now running. You can view your session in the link above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858f0f6-9aca-4cdb-a514-9fbf7e353d50",
   "metadata": {},
   "source": [
    "AG2 will now start automatically tracking\n",
    "\n",
    "* LLM prompts and completions\n",
    "* Token usage and costs\n",
    "* Agent names and actions\n",
    "* Correspondence between agents\n",
    "* Tool usage\n",
    "* Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc592637",
   "metadata": {},
   "source": [
    "# Tool Example\n",
    "AgentOps tracks when AG2 agents use tools. You can find more information on this example in [tool-use.ipynb](https://docs.ag2.ai/docs/tutorial/tool-use#tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4dfe37-85e0-4035-a314-3459c6e378c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\conversable_agent.py:2996: UserWarning: Function 'calculator' is being overridden.\n",
      "  warnings.warn(f\"Function '{tool_sig['function']['name']}' is being overridden.\", UserWarning)\n",
      "C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\conversable_agent.py:2905: UserWarning: Function 'calculator' is being overridden.\n",
      "  warnings.warn(f\"Function '{name}' is being overridden.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What is (1423 - 123) / 3 + (32 + 23) * 5?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_200j96eatOaZnTf7FmD46Cti): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 1423, \"b\": 123, \"operator\": \"-\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_ezUIWB1TrSKVuqLvV9h4N1Hh): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 32, \"b\": 23, \"operator\": \"+\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: [opentelemetry.attributes] Invalid type dict for attribute 'tool.name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\n",
      "Call ID: call_200j96eatOaZnTf7FmD46Cti\n",
      "Input arguments: {'a': 1423, 'b': 123, 'operator': '-'}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: [opentelemetry.attributes] Invalid type dict for attribute 'tool.name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\n",
      "Call ID: call_ezUIWB1TrSKVuqLvV9h4N1Hh\n",
      "Input arguments: {'a': 32, 'b': 23, 'operator': '+'}\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_200j96eatOaZnTf7FmD46Cti) *****\u001b[0m\n",
      "1300\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m***** Response from calling tool (call_ezUIWB1TrSKVuqLvV9h4N1Hh) *****\u001b[0m\n",
      "55\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_C35g3JHTHjb9do7MqqGvoNin): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 1300, \"b\": 3, \"operator\": \"/\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_WH1jvrIQWgiYOfu1XnqGOnoY): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 55, \"b\": 5, \"operator\": \"*\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: [opentelemetry.attributes] Invalid type dict for attribute 'tool.name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\n",
      "Call ID: call_C35g3JHTHjb9do7MqqGvoNin\n",
      "Input arguments: {'a': 1300, 'b': 3, 'operator': '/'}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: [opentelemetry.attributes] Invalid type dict for attribute 'tool.name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\n",
      "Call ID: call_WH1jvrIQWgiYOfu1XnqGOnoY\n",
      "Input arguments: {'a': 55, 'b': 5, 'operator': '*'}\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_C35g3JHTHjb9do7MqqGvoNin) *****\u001b[0m\n",
      "433\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m***** Response from calling tool (call_WH1jvrIQWgiYOfu1XnqGOnoY) *****\u001b[0m\n",
      "275\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_zw2MlYqxdjNSyVFlP1IgntY6): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\":433,\"b\":275,\"operator\":\"+\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 🖇 AgentOps: [opentelemetry.attributes] Invalid type dict for attribute 'tool.name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\n",
      "Call ID: call_zw2MlYqxdjNSyVFlP1IgntY6\n",
      "Input arguments: {'a': 433, 'b': 275, 'operator': '+'}\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_zw2MlYqxdjNSyVFlP1IgntY6) *****\u001b[0m\n",
      "708\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "The result of the calculation (1423 - 123) / 3 + (32 + 23) * 5 is 708.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define model, openai api key, tags, etc in the agent configuration\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"api_key\": OPENAI_API_KEY,\n",
    "        \"tags\": [\"mathagent-example\", \"tool\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")\n",
    "\n",
    "\n",
    "# Create the agent that uses the LLM.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can help with simple calculations. \"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None\n",
    "    and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(\n",
    "    calculator\n",
    ")\n",
    "user_proxy.register_for_execution(name=\"calculator\")(calculator)\n",
    "\n",
    "# Register the calculator function to the two agents.\n",
    "register_function(\n",
    "    calculator,\n",
    "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"calculator\",  # By default, the function name is used as the tool name.\n",
    "    description=\"A simple calculator\",  # A description of the tool.\n",
    ")\n",
    "\n",
    "# Let the assistant start the conversation.  It will end when the user types \"exit\".\n",
    "try:\n",
    "    user_proxy.initiate_chat(\n",
    "        assistant, message=\"What is (1423 - 123) / 3 + (32 + 23) * 5?\"\n",
    "    )\n",
    "except StdinNotImplementedError:\n",
    "    # This is only necessary for AgentOps testing automation which is headless and will not have user input\n",
    "    print(\"Stdin not implemented. Skipping initiate_chat\")\n",
    "    agentops.end_session(\"Indeterminate\")\n",
    "\n",
    "agentops.end_session(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b0305-1247-489e-b1b0-829127af76d3",
   "metadata": {},
   "source": [
    "You can see your run in action at [app.agentops.ai](app.agentops.ai). In this example, the AgentOps dashboard will show:\n",
    "\n",
    "* Agents talking to each other\n",
    "* Each use of the `calculator` tool\n",
    "* Each call to OpenAI for LLM use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
