{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6538d8-2a5d-4a99-b2c1-7130963e4f7b",
   "metadata": {},
   "source": [
    "# AG2 Chat Example\n",
    "<img src=\"https://raw.githubusercontent.com/AgentOps-AI/agentops/main/docs/images/external/autogen/autogen-integration.png?raw=true\" width=\"25%\"/>\n",
    "\n",
    "AgentOps automatically configures itself when it's initialized meaning your agent run data will be tracked and logged to your AgentOps dashboard right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87626697",
   "metadata": {},
   "source": [
    "First let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pyautogen\n",
    "%pip install -U agentops\n",
    "%pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506f401",
   "metadata": {},
   "source": [
    "Then import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5c8b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_72632\\938258297.py\", line 1, in <module>\n",
      "    from autogen import ConversableAgent, UserProxyAgent\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\__init__.py\", line 9, in <module>\n",
      "    from .agentchat import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\__init__.py\", line 12, in <module>\n",
      "    from .contrib.swarm_agent import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\contrib\\swarm_agent.py\", line 22, in <module>\n",
      "    from ..groupchat import SELECT_SPEAKER_PROMPT_TEMPLATE, GroupChat, GroupChatManager\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\agentchat\\groupchat.py\", line 19, in <module>\n",
      "    from ..graph_utils import check_graph_validity, invert_disallowed_to_allowed\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\autogen\\graph_utils.py\", line 15, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py\", line 174, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\ticker.py\", line 143, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "import agentops\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.error import (\n",
    "    StdinNotImplementedError,\n",
    ")  # only needed by AgentOps testing automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b502a2",
   "metadata": {},
   "source": [
    "Next, we'll set our API keys. There are several ways to do this, the code below is just the most foolproof way for the purposes of this notebook. It accounts for both users who use environment variables and those who just want to set the API Key here in this notebook.\n",
    "\n",
    "[Get an AgentOps API key](https://agentops.ai/settings/projects)\n",
    "\n",
    "1. Create an environment variable in a .env file or other method. By default, the AgentOps `init()` function will look for an environment variable named `AGENTOPS_API_KEY`. Or...\n",
    "\n",
    "2. Replace `<your_agentops_key>` below and pass in the optional `api_key` parameter to the AgentOps `init(api_key=...)` function. Remember not to commit your API key to a public repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae4152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or \"<your_openai_key>\"\n",
    "AGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\") or \"<your_agentops_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93f2339-7b99-4cf1-9232-c24faba49c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) ðŸ–‡ AgentOps: Including project_id in resource attributes: fd6006a1-e230-4416-b1c7-f442d195a718\n",
      "(DEBUG) ðŸ–‡ AgentOps: Tracing core initialized\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented OpenAIInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented AnthropicInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented CohereInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: [opentelemetry.trace] Overriding of current TracerProvider is not allowed\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented CrewAIInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented GroqInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: [opentelemetry.instrumentation.instrumentor] DependencyConflict: requested: \"haystack-ai >= 2.0.0\" but found: \"haystack-ai 2.11.0rc0\"\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented HaystackInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented MistralAiInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Package ollama not found; skipping instrumentation of OllamaInstrumentor\n",
      "(DEBUG) ðŸ–‡ AgentOps: Instrumented AgentsInstrumentor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentOps is now running. You can view your session in the link above\n"
     ]
    }
   ],
   "source": [
    "# When initializing AgentOps, you can pass in optional tags to help filter sessions\n",
    "agentops.init(api_key=AGENTOPS_API_KEY, default_tags=[\"simple-autogen-example\"])\n",
    "\n",
    "print(\"AgentOps is now running. You can view your session in the link above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858f0f6-9aca-4cdb-a514-9fbf7e353d50",
   "metadata": {},
   "source": [
    "AutoGen will now start automatically tracking\n",
    "\n",
    "* LLM prompts and completions\n",
    "* Token usage and costs\n",
    "* Agent names and actions\n",
    "* Correspondence between agents\n",
    "* Tool usage\n",
    "* Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875dd0c",
   "metadata": {},
   "source": [
    "# Simple Chat Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2962d990-f7ef-43d8-ba09-d29bd8356d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "How can I help you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "hi\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Success! Visit your AgentOps dashboard to see the replay\n"
     ]
    }
   ],
   "source": [
    "# Define model, openai api key, tags, etc in the agent configuration\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"api_key\": OPENAI_API_KEY,\n",
    "        \"tags\": [\"agentchat-example\", \"chat\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the agent that uses the LLM.\n",
    "assistant = ConversableAgent(\"agent\", llm_config={\"config_list\": config_list})\n",
    "\n",
    "# Create the agent that represents the user in the conversation.\n",
    "user_proxy = UserProxyAgent(\"user\", code_execution_config=False)\n",
    "\n",
    "# Let the assistant start the conversation.  It will end when the user types \"exit\".\n",
    "try:\n",
    "    assistant.initiate_chat(user_proxy, message=\"How can I help you today?\")\n",
    "except StdinNotImplementedError:\n",
    "    # This is only necessary for AgentOps testing automation which is headless and will not have user input\n",
    "    print(\"Stdin not implemented. Skipping initiate_chat\")\n",
    "    agentops.end_session(\"Indeterminate\")\n",
    "\n",
    "# Close your AgentOps session to indicate that it completed.\n",
    "agentops.end_session(\"Success\")\n",
    "print(\"Success! Visit your AgentOps dashboard to see the replay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b422137-903a-41ef-a4ca-95b50aea4138",
   "metadata": {},
   "source": [
    "You can view data on this run at [app.agentops.ai](app.agentops.ai).\n",
    "\n",
    "The dashboard will display LLM events for each message sent by each agent, including those made by the human user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
