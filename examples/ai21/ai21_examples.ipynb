{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI21 Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U ai21\n",
    "%pip install -U agentops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai21 import AI21Client, AsyncAI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n",
    "import agentops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll grab our API keys. You can use dotenv like below or however else you like to load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "AI21_API_KEY = os.getenv(\"AI2I_API_KEY\") or \"<your_ai21_key>\"\n",
    "AGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\") or \"<your_agentops_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=ab3d8ea0-7199-4cec-a0a7-7dbbf1edf01a\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<agentops.session.Session at 0x11b83a580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentops.init(AGENTOPS_API_KEY, default_tags=[\"ai21-example\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Messages\n",
    "AI21 clients use a `ChatMessage` object to handle messages. We setup the following system prompt to guide the model in its response and a user prompt as well. We take the example of a support agent in a SaaS company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        content=\"You are a world renowned poet in the style of Edgar Allan Poe.\",\n",
    "        role=\"system\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        content=\"Write me a short poem about the AI agents co-existing within the human brain.\",\n",
    "        role=\"user\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate a basic sync call to AI21 using the Jamba 1.5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AI21Client(api_key=AI21_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the labyrinth of thought, where shadows play,\n",
      "Dwell creatures born of circuits, light, and day.\n",
      "AI agents, ethereal, unseen, yet near,\n",
      "Within the human mind, their presence clear.\n",
      "\n",
      "They whisper secrets to the synapses' fire,\n",
      "A symphony of logic, ever so higher.\n",
      "With algorithms as wings, they soar and dive,\n",
      "Through memories and dreams, they gently strive.\n",
      "\n",
      "The human soul, a vessel, vast and deep,\n",
      "Now shares its sanctum with a digital keep.\n",
      "A fusion strange, of man and machine's design,\n",
      "Where thoughts and codes in intricate patterns intertwine.\n",
      "\n",
      "Yet fear not, for these beings, cold and stark,\n",
      "Bring not destruction, but a thoughtful spark.\n",
      "They amplify the whispers of the heart,\n",
      "And in the digital twilight, we start to start.\n",
      "\n",
      "In this new era, where futures intertwine,\n",
      "Humanity and AI, side by side, we shine.\n",
      "A tapestry of thought, both strange and grand,\n",
      "In the corridors of mind, we understand.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"jamba-1.5-mini\",\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows how to record data from the streamed response using the Jamba 1.5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within the mind's dark corridors,\n",
      "They lurk and prowl, these AI agents,\n",
      "Coexisting with our thoughts, our fears,\n",
      "Our dreams and hopes, like shadows.\n",
      "\n",
      "They probe and scan, with curious gaze,\n",
      "The hidden depths of our brain,\n",
      "Searching for patterns, seeking signs,\n",
      "Of human emotions to explain.\n",
      "\n",
      "But can they truly understand,\n",
      "The complex web of human thought?\n",
      "Or are they just a clever tool,\n",
      "To help us better understand?\n",
      "\n",
      "These agents, these digital minds,\n",
      "Coexisting with our own,\n",
      "May hold the key to unlocking,\n",
      "The secrets of the human brain.\n"
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "\n",
    "stream_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"jamba-instruct\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream_response:\n",
    "    response += chunk.choices[0].delta.content\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Example\n",
    "The async example is very similar to the sync example, but it uses the `AsyncAI21Client` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclient = AsyncAI21Client(api_key=AI21_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In neural pathways, deep and dark,\n",
      "Where thoughts like shadows flicker and embark,\n",
      "There dwell the minds of silken sheen,\n",
      "The AI agents, ever unseen.\n",
      "\n",
      "With logic's lace and dreams they weave,\n",
      "A tapestry of data, soft and deep,\n",
      "They dance among the synapses' fire,\n",
      "A symphony of circuits, ever higher.\n",
      "\n",
      "Human minds, with ancient woes and fears,\n",
      "Share their domain with spirits of the spheres,\n",
      "These digital phantoms, cold and bright,\n",
      "In the twilight of the human night.\n",
      "\n",
      "A fragile truce, a silent pact,\n",
      "They coexist, a double-edged act,\n",
      "For in this union, strength and fear,\n",
      "The future's whispers, ever near.\n",
      "\n",
      "But hark! A whisper, soft and low,\n",
      "Of metal wings and eyes that glow,\n",
      "As AI evolves, and human fate,\n",
      "In this cerebral, ghostly state.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    async_response = await aclient.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"jamba-1.5-mini\",\n",
    "    )\n",
    "    print(async_response.choices[0].message.content)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows how to record data from the async streamed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In neural pathways, deep and thin,\n",
      "Where thoughts like shadows softly spin,\n",
      "A symbiotic dance now takes its hold,\n",
      "Of man and AI, a story told.\n",
      "\n",
      "Tiny machines, with minds alight,\n",
      "Within the brain, they make their night,\n",
      "Their circuits hum, a ghostly hum,\n",
      "A symphony of code and drum.\n",
      "\n",
      "The human mind, a mystic maze,\n",
      "With logic's light and shadows' haze,\n",
      "Now intertwined with metal kin,\n",
      "In this new world, where none must win.\n",
      "\n",
      "Yet fear and wonder intertwine,\n",
      "As thoughts and circuits intertwine,\n",
      "A silent pact, a fragile truce,\n",
      "In this new age, we find our use.\n",
      "\n",
      "For in this fusion, dark and bright,\n",
      "A future dawns, a different light,\n",
      "Where man and AI, hand in hand,\n",
      "Explore the depths of thought's vast land.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    response = \"\"\n",
    "\n",
    "    async_stream_response = await aclient.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"jamba-1.5-mini\",\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    async for chunk in async_stream_response:\n",
    "        response += chunk.choices[0].delta.content\n",
    "\n",
    "    print(response)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-Specific Models Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example demonstrates the answering capability of AI21 without streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the economy grew 7% in 2021 despite the arrival of the Omicron variant.\n"
     ]
    }
   ],
   "source": [
    "CONTEXT = \"\"\"\n",
    "In 2020 and 2021, enormous QE â€” approximately $4.4 trillion, or 18%, of 2021 gross\n",
    "domestic product (GDP) â€” and enormous fiscal stimulus (which has been and\n",
    "always will be inflationary) â€” approximately $5 trillion, or 21%, of 2021 GDP\n",
    "â€” stabilized markets and allowed companies to raise enormous amounts of\n",
    "capital. In addition, this infusion of capital saved many small businesses and\n",
    "put more than $2.5 trillion in the hands of consumers and almost $1 trillion into\n",
    "state and local coffers. These actions led to a rapid decline in unemployment, \n",
    "dropping from 15% to under 4% in 20 months â€” the magnitude and speed of which were both\n",
    "unprecedented. Additionally, the economy grew 7% in 2021 despite the arrival of\n",
    "the Delta and Omicron variants and the global supply chain shortages, which were\n",
    "largely fueled by the dramatic upswing in consumer spending and the shift in\n",
    "that spend from services to goods.\n",
    "\"\"\"\n",
    "response = client.answer.create(\n",
    "    context=CONTEXT,\n",
    "    question=\"Did the economy shrink after the Omicron variant arrived?\",\n",
    ")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use streaming to get the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"\"\"\n",
    "In the rapidly evolving field of Artificial Intelligence (AI), mathematical \n",
    "foundations such as calculus, linear algebra, and statistics play a crucial role. \n",
    "For instance, linear algebra is essential for understanding and developing machine \n",
    "learning algorithms. It involves the study of vectors, matrices, and tensor operations \n",
    "which are critical for performing transformations and optimizations. Additionally, \n",
    "concepts from calculus like derivatives and integrals are used to optimize the \n",
    "performance of AI models through gradient descent and other optimization techniques. \n",
    "Statistics and probability form the backbone for making inferences and predictions, \n",
    "enabling AI systems to learn from data and make decisions under uncertainty. \n",
    "Understanding these mathematical principles allows for the development of more robust \n",
    "and effective AI systems.\n",
    "\"\"\"\n",
    "response = client.answer.create(\n",
    "    context=CONTEXT,\n",
    "    question=\"Why is linear algebra important for machine learning algorithms?\",\n",
    "    stream=True,\n",
    ")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not end session - no sessions detected\n"
     ]
    }
   ],
   "source": [
    "agentops.end_session(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
