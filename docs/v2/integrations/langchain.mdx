---
title: LangChain
description: "Track your LangChain agents with AgentOps"
---

[LangChain](https://python.langchain.com/docs/tutorials/) is a framework for developing applications powered by language models. AgentOps automatically tracks your LangChain agents by integrating its callback handler.

## Installation

Install AgentOps and the necessary LangChain dependencies:

<CodeGroup>
  ```bash pip
  pip install agentops langchain langchain-community langchain-openai python-dotenv
  ```
  ```bash poetry
  poetry add agentops langchain langchain-community langchain-openai python-dotenv
  ```
  ```bash uv
  uv add agentops langchain langchain-community langchain-openai python-dotenv
  ```
</CodeGroup>

## Setting Up API Keys

You'll need API keys for AgentOps and OpenAI (as `ChatOpenAI` is commonly used with LangChain):
- **OPENAI_API_KEY**: From the [OpenAI Platform](https://platform.openai.com/api-keys)
- **AGENTOPS_API_KEY**: From your [AgentOps Dashboard](https://app.agentops.ai/)

Set these as environment variables or in a `.env` file.

<CodeGroup>
  ```bash Export to CLI
  export OPENAI_API_KEY="your_openai_api_key_here"
  export AGENTOPS_API_KEY="your_agentops_api_key_here"
  ```
  ```txt Set in .env file
  OPENAI_API_KEY="your_openai_api_key_here"
  AGENTOPS_API_KEY="your_agentops_api_key_here"
  ```
</CodeGroup>

Then load them in your Python code:
```python
from dotenv import load_dotenv
import os

load_dotenv()

AGENTOPS_API_KEY = os.getenv("AGENTOPS_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
```

## Usage

Integrating AgentOps with LangChain involves using the `LangchainCallbackHandler`.
<Tip>
You don't need a separate `agentops.init()` call; the `LangchainCallbackHandler` initializes the AgentOps client automatically if an API key is provided to it or found in the environment.
</Tip>

Here's a basic example:

```python
from langchain_community.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, AgentType, Tool # Corrected Tool import
from langchain.tools import DuckDuckGoSearchRun # Example tool
from agentops.integration.callbacks.langchain import LangchainCallbackHandler


# 1. Initialize LangchainCallbackHandler
# AGENTOPS_API_KEY can be passed here or loaded from environment
handler = LangchainCallbackHandler(api_key=AGENTOPS_API_KEY, tags=['LangChain Example'])

# 2. Define tools for the agent
search_tool = DuckDuckGoSearchRun()
tools = [
    Tool( # Wrap DuckDuckGoSearchRun in a Tool object
        name="DuckDuckGo Search",
        func=search_tool.run,
        description="Useful for when you need to answer questions about current events or the current state of the world."
    )
]

# 3. Configure LLM with the AgentOps handler
# OPENAI_API_KEY can be passed here or loaded from environment
llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,
                 callbacks=[handler],
                 model='gpt-3.5-turbo',
                 temperature=0) # Added temperature for reproducibility

# 4. Initialize your agent, passing the handler to callbacks
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    callbacks=[handler], 
    handle_parsing_errors=True
)

# 5. Run your agent
try:
    response = agent.run("Who is the current CEO of OpenAI and what is his most recent public statement?")
    print(response)
except Exception as e:
    print(f"An error occurred: {e}")
```

Visit the [AgentOps Dashboard](https://app.agentops.ai/) to see your session.

## Examples
<CardGroup cols={1}>
  <Card title="LangChain Example" icon="notebook" href="/v2/examples/langchain">
    A detailed notebook demonstrating the LangChain callback handler integration.
  </Card>
</CardGroup>

<script type="module" src="/scripts/github_stars.js"></script>
<script type="module" src="/scripts/scroll-img-fadein-animation.js"></script>
<script type="module" src="/scripts/button_heartbeat_animation.js"></script>
<script type="css" src="/styles/styles.css"></script>
<script type="module" src="/scripts/adjust_api_dynamically.js"></script>
