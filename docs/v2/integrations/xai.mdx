---
title: xAI (Grok)
description: "Track and analyze your xAI Grok API calls with AgentOps"
---

import CodeTooltip from '/snippets/add-code-tooltip.mdx'
import EnvTooltip from '/snippets/add-env-tooltip.mdx'

AgentOps can track Grok. Grok is this true?

## Installation

<CodeTooltip />

<CodeGroup>
  ```bash pip
  pip install agentops openai
  ```
  ```bash poetry
  poetry add agentops openai
  ```
  ```bash uv
  uv add agentops openai
  ```
</CodeGroup>

## Setting Up API Keys

Before using xAI with AgentOps, you need to set up your API keys. You can obtain:
- **XAI_API_KEY**: From the [xAI Developer Platform](https://console.x.ai/)
- **AGENTOPS_API_KEY**: From your [AgentOps Dashboard](https://app.agentops.ai/)

Then to set them up, you can either export them as environment variables or set them in a `.env` file.

<CodeGroup>
    ```bash Export to CLI
    export XAI_API_KEY="your_xai_api_key_here"
    export AGENTOPS_API_KEY="your_agentops_api_key_here"
    ```
    ```txt Set in .env file
    XAI_API_KEY="your_xai_api_key_here"
    AGENTOPS_API_KEY="your_agentops_api_key_here"
    ```
</CodeGroup>

Then load the environment variables in your Python code:

```python
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()

# Set up environment variables with fallback values
os.environ["XAI_API_KEY"] = os.getenv("XAI_API_KEY")
os.environ["AGENTOPS_API_KEY"] = os.getenv("AGENTOPS_API_KEY")
```

## Usage

Initialize AgentOps at the beginning of your application. Then, use the OpenAI SDK with xAI's base URL to interact with Grok. AgentOps will automatically track all API calls.

<CodeGroup>
```python Basic Chat Usage
import agentops
import os
from openai import OpenAI

# Initialize AgentOps
agentops.init()

# Create OpenAI client configured for xAI
client = OpenAI(
    api_key=os.getenv("XAI_API_KEY"),
    base_url="https://api.x.ai/v1",
)

# Basic chat completion
completion = client.chat.completions.create(
    model="grok-3-latest",
    messages=[
        {"role": "system", "content": "You are a helpful AI assistant."},
        {"role": "user", "content": "Explain the concept of AI observability in simple terms."},
    ],
)

print(completion.choices[0].message.content)
```

```python Streaming Chat
import agentops
import os
from openai import OpenAI

# Initialize AgentOps
agentops.init()

# Create OpenAI client configured for xAI
client = OpenAI(
    api_key=os.getenv("XAI_API_KEY"),
    base_url="https://api.x.ai/v1",
)

# Streaming chat completion
stream = client.chat.completions.create(
    model="grok-3-latest",
    messages=[
        {"role": "system", "content": "You are a helpful AI assistant."},
        {"role": "user", "content": "Tell me about the latest developments in AI."},
    ],
    stream=True,
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```
</CodeGroup>

## Streaming

xAI supports streaming responses through the OpenAI SDK. The streaming example above shows how to process response chunks as they are generated by the model. AgentOps will automatically track both regular and streaming interactions.

## Examples

Examples are available in the [AgentOps repository](https://github.com/AgentOps-AI/agentops/tree/main/examples/xai).

<script type="module" src="/scripts/github_stars.js"></script>
<script type="module" src="/scripts/scroll-img-fadein-animation.js"></script>
<script type="module" src="/scripts/button_heartbeat_animation.js"></script>
<script type="css" src="/styles/styles.css"></script>
