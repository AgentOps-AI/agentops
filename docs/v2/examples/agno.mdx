---
title: Agno
description: "Comprehensive examples of using Agno with AgentOps instrumentation"
---

This guide provides complete examples of using [Agno](https://docs.agno.com) with AgentOps instrumentation. You'll learn how to create agents, coordinate teams, build workflows, and leverage advanced features like RAG and async operations.

## Prerequisites

Before running these examples, ensure you have:

1. **API Keys**: AgentOps and OpenAI API keys
2. **Environment Setup**: Python environment with required packages
3. **Dependencies**: Install Agno and AgentOps

<CodeGroup>
  ```bash pip
  pip install agentops agno 
  ```
  ```bash poetry
  poetry add agentops agno 
  ```
  ```bash uv
  uv add agentops agno 
  ```
</CodeGroup>

## Environment Configuration

Create a `.env` file with your API keys:

```env
AGENTOPS_API_KEY="your_agentops_api_key_here"
OPENAI_API_KEY="your_openai_api_key_here"
```

## Complete Example Structure

Here's the foundation for all our examples:

```python
"""
Comprehensive Agno Example with AgentOps Instrumentation

This example demonstrates key Agno features:
1. Basic Agents and Teams
2. Tool Integration with RAG
3. Workflows with Caching
4. Collaborative Research Teams
5. Async Operations
"""

import os
import asyncio
from typing import Iterator
from textwrap import dedent
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import Agno components
from agno.agent import Agent, RunResponse
from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow
from agno.tools.reasoning import ReasoningTools
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.hackernews import HackerNewsTools
from agno.tools.arxiv import ArxivTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.knowledge.url import UrlKnowledge
from agno.utils.pprint import pprint_run_response
from agno.utils.log import logger

# Initialize AgentOps
import agentops
agentops.init(api_key=os.getenv("AGENTOPS_API_KEY"))

# Configuration
MODEL_NAME = "gpt-4o-mini"

def check_environment():
    """Check if required environment variables are set."""
    required_vars = ["AGENTOPS_API_KEY", "OPENAI_API_KEY"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"Missing required environment variables: {missing_vars}")
        print("Please set these in your .env file or environment")
        return False
    
    print("Environment variables checked successfully")
    return True
```

## 1. Basic Agents and Teams

### Creating and Running Individual Agents

```python
def demonstrate_basic_agents():
    """Demonstrate basic agent creation and team coordination."""
    print("\n" + "=" * 60)
    print("BASIC AGENTS AND TEAMS")
    print("=" * 60)

    try:
        # Create individual agents with specific roles
        news_agent = Agent(
            name="News Agent", 
            role="Get the latest news",
            model=OpenAIChat(id=MODEL_NAME)
        )

        weather_agent = Agent(
            name="Weather Agent", 
            role="Get the weather for the next 7 days",
            model=OpenAIChat(id=MODEL_NAME)
        )

        # Create a team with coordination mode
        team = Team(
            name="News and Weather Team", 
            mode="coordinate",  # Agents work in sequence
            members=[news_agent, weather_agent]
        )

        # Run team task - AgentOps will track all interactions
        response = team.run("What is the weather in Tokyo?")
        print(f"Team Response: {response.content}")
        
    except Exception as e:
        print(f"Basic agents error: {e}")

# Run the example
demonstrate_basic_agents()
```

/v2/introduction
## 2. Tool Integration with RAG

### Knowledge Base and Advanced Tools

```python
def demonstrate_tool_integration():
    """Demonstrate tool integration with RAG and knowledge base."""
    print("\n" + "=" * 60)
    print("TOOL INTEGRATION WITH RAG")
    print("=" * 60)

    try:
        # Create knowledge base with vector database
        knowledge_base = UrlKnowledge(
            urls=["https://docs.agno.com/introduction/agents.md"],
            # Use LanceDB for vector storage
            vector_db=LanceDb(
                uri="tmp/lancedb",
                table_name="agno_docs",
                search_type=SearchType.hybrid,
                embedder=CohereEmbedder(id="embed-v4.0"),
                reranker=CohereReranker(model="rerank-v3.5"),
            ),
        )

        # Create agent with knowledge and reasoning tools
        agent = Agent(
            model=OpenAIChat(id=MODEL_NAME),
            # Agentic RAG is enabled with knowledge
            knowledge=knowledge_base,
            search_knowledge=True,  # Enable on-demand search
            tools=[ReasoningTools(add_instructions=True)],
            instructions=[
                "Include sources in your response.",
                "Always search your knowledge before answering the question.",
                "Only include the output in your response. No other text.",
            ],
            markdown=True,
        )
        
        print("Running RAG agent with knowledge base...")
        agent.print_response(
            "What are Agents?",
            show_full_reasoning=True,
        )
        
    except Exception as e:
        print(f"Tool integration error: {e}")

# Run the example
demonstrate_tool_integration()
```

## 3. Workflows with Caching

### State Management and Optimization

```python
class CacheWorkflow(Workflow):
    """A workflow that demonstrates caching capabilities."""
    
    description: str = "A workflow that caches previous outputs"
    agent = Agent(model=OpenAIChat(id=MODEL_NAME))

    def run(self, message: str) -> Iterator[RunResponse]:
        logger.info(f"Checking cache for '{message}'")
        
        # Check if the output is already cached
        if self.session_state.get(message):
            logger.info(f"Cache hit for '{message}'")
            yield RunResponse(
                run_id=self.run_id, 
                content=self.session_state.get(message)
            )
            return

        logger.info(f"Cache miss for '{message}'")
        
        # Run the agent and yield the response
        yield from self.agent.run(message, stream=True)
        
        # Cache the output after response is yielded
        self.session_state[message] = self.agent.run_response.content

def demonstrate_workflows():
    """Demonstrate workflow capabilities with caching."""
    print("\n" + "=" * 60)
    print("WORKFLOWS WITH CACHING")
    print("=" * 60)

    try:
        workflow = CacheWorkflow()

        print("First run (cache miss):")
        # This takes ~1s as it generates new content
        response = workflow.run(message="Tell me a joke.")
        pprint_run_response(response, markdown=True, show_time=True)
        
        print("\nSecond run (cache hit):")
        # This is immediate due to caching
        response = workflow.run(message="Tell me a joke.")
        pprint_run_response(response, markdown=True, show_time=True)
        
    except Exception as e:
        print(f"Workflow error: {e}")

# Run the example
demonstrate_workflows()
```


## 4. Collaborative Research Teams

### Multi-Agent Coordination

```python
def demonstrate_research_team():
    """Demonstrate collaborative research team with multiple specialized agents."""
    print("\n" + "=" * 60)
    print("COLLABORATIVE RESEARCH TEAM")
    print("=" * 60)

    try:
        # Create specialized research agents
        reddit_researcher = Agent(
            name="Reddit Researcher",
            role="Research a topic on Reddit",
            model=OpenAIChat(id="gpt-4o"),
            tools=[GoogleSearchTools()],
            add_name_to_instructions=True,
            instructions=dedent("""
                You are a Reddit researcher.
                You will be given a topic to research on Reddit.
                You will need to find the most relevant posts on Reddit.
            """),
        )

        hackernews_researcher = Agent(
            name="HackerNews Researcher",
            model=OpenAIChat("gpt-4o"),
            role="Research a topic on HackerNews.",
            tools=[HackerNewsTools()],
            add_name_to_instructions=True,
            instructions=dedent("""
                You are a HackerNews researcher.
                You will be given a topic to research on HackerNews.
                You will need to find the most relevant posts on HackerNews.
            """),
        )

        academic_paper_researcher = Agent(
            name="Academic Paper Researcher",
            model=OpenAIChat("gpt-4o"),
            role="Research academic papers and scholarly content",
            tools=[GoogleSearchTools(), ArxivTools()],
            add_name_to_instructions=True,
            instructions=dedent("""
                You are an academic paper researcher.
                You will be given a topic to research in academic literature.
                You will need to find relevant scholarly articles, papers, and academic discussions.
                Focus on peer-reviewed content and citations from reputable sources.
                Provide brief summaries of key findings and methodologies.
            """),
        )

        twitter_researcher = Agent(
            name="Twitter Researcher",
            model=OpenAIChat("gpt-4o"),
            role="Research trending discussions and real-time updates",
            tools=[DuckDuckGoTools()],
            add_name_to_instructions=True,
            instructions=dedent("""
                You are a Twitter/X researcher.
                You will be given a topic to research on Twitter/X.
                You will need to find trending discussions, influential voices, and real-time updates.
                Focus on verified accounts and credible sources when possible.
                Track relevant hashtags and ongoing conversations.
            """),
        )

        # Create collaborative team
        agent_team = Team(
            name="Discussion Team",
            mode="collaborate",  # Agents work together
            model=OpenAIChat("gpt-4o"),
            members=[
                reddit_researcher,
                hackernews_researcher,
                academic_paper_researcher,
                twitter_researcher,
            ],
            instructions=[
                "You are a discussion master.",
                "You have to stop the discussion when you think the team has reached a consensus.",
            ],
            success_criteria="The team has reached a consensus.",
            enable_agentic_context=True,
            add_context=True,
            show_tool_calls=True,
            markdown=True,
            debug_mode=True,
            show_members_responses=True,
        )

        print("Running collaborative research team...")
        agent_team.print_response(
            message="Start the discussion on the topic: 'What is the best way to learn to code?'",
            stream=True,
            stream_intermediate_steps=True,
        )
        
    except Exception as e:
        print(f"Research team error: {e}")

# Run the example
demonstrate_research_team()
```

## 5. Async Operations

### Concurrent Agent Execution

```python
async def demonstrate_async_operations():
    """Demonstrate async operations with Agno agents."""
    print("\n" + "=" * 60)
    print("ASYNC OPERATIONS")
    print("=" * 60)

    try:
        # Create agent for async operations
        agent = Agent(model=OpenAIChat(id=MODEL_NAME))
        
        # Define async tasks
        async def task1():
            response = await agent.arun("Explain Python in one paragraph")
            return f"Task 1: {response.content}"
        
        async def task2():
            response = await agent.arun("Explain JavaScript in one paragraph")
            return f"Task 2: {response.content}"
        
        async def task3():
            response = await agent.arun("Compare them briefly")
            return f"Task 3: {response.content}"
        
        # Run tasks concurrently for better performance
        print("Running async tasks concurrently...")
        results = await asyncio.gather(task1(), task2(), task3())
        
        for result in results:
            print(result)
            print()
            
    except Exception as e:
        print(f"Async operations error: {e}")

# Run async example
asyncio.run(demonstrate_async_operations())
```

## Complete Running Example

Here's how to run all examples together:

```python
async def main():
    """Main function to run all Agno demonstrations."""
    print("Starting Comprehensive Agno Example with AgentOps")
    print("=" * 80)
    
    # Check environment first
    if not check_environment():
        return
    
    print("\nRunning all Agno demonstrations...")
    
    # Run all demonstrations with error handling
    demos = [
        ("Basic Agents", demonstrate_basic_agents),
        ("Tool Integration", demonstrate_tool_integration),
        ("Workflows", demonstrate_workflows),
        ("Research Team", demonstrate_research_team),
    ]
    
    for name, demo_func in demos:
        try:
            demo_func()
        except Exception as e:
            print(f"Skipping {name} demo due to: {e}")
    
    # Run async demo
    try:
        await demonstrate_async_operations()
    except Exception as e:
        print(f"Skipping async demo due to: {e}")
    
    print("\nAll Agno demonstrations completed!")
    print("Check your AgentOps dashboard for detailed traces and metrics.")

if __name__ == "__main__":
    asyncio.run(main())
```

## Monitoring and Analytics

### AgentOps Dashboard Features

After running these examples, visit your [AgentOps Dashboard](https://app.agentops.ai/) to see:

**Agent Analytics:**
- Individual agent performance metrics
- Token usage and costs per agent
- Response times and success rates
- Agent interaction patterns

**Team Coordination:**
- Multi-agent collaboration flows
- Team decision-making processes
- Communication patterns between agents
- Task distribution and load balancing

**Workflow Optimization:**
- Cache efficiency metrics
- Workflow state transitions
- Performance bottlenecks
- Resource utilization

**Tool Usage:**
- Tool execution frequency and success rates
- RAG query performance
- Knowledge base retrieval accuracy
- Custom tool effectiveness

## Best Practices from Examples

1. **Environment Management**: Always validate API keys before running agents
2. **Error Handling**: Wrap each demo in try-catch for robust execution
3. **Resource Optimization**: Use caching workflows for repeated operations
4. **Team Design**: Create specialized agents with clear, distinct roles
5. **Async Operations**: Leverage concurrent execution for improved performance
6. **Monitoring**: Use AgentOps dashboard to optimize agent performance


## Next Steps

- Explore the [Agno Integration Guide](/v2/integrations/agno) for more advanced configurations
- Check out additional [AgentOps Examples](/examples) for other frameworks
- Visit the [AgentOps Dashboard](https://app.agentops.ai/) to monitor your agents
- Join the [AgentOps Community](https://discord.gg/agentops) for support and discussions 