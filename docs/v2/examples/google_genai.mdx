---
title: 'Google GenAI'
description: 'Google Generative AI Example with AgentOps'
---
{/*  SOURCE_FILE: examples/google_genai/gemini_example.ipynb  */}

_View Notebook on <a href={'https://github.com/AgentOps-AI/agentops/blob/main/examples/google_genai/gemini_example.ipynb'} target={'_blank'}>Github</a>_

# Google Generative AI Example with AgentOps

This notebook demonstrates how to use AgentOps with Google's Generative AI package for observing both synchronous and streaming text generation.




## Installation
<CodeGroup>
  ```bash pip
  pip install agentops google-genai
  ```
  ```bash poetry
  poetry add agentops google-genai
  ```
  ```bash uv
  uv pip install agentops google-genai
  ```
</CodeGroup>

```python
from google import genai
import agentops
from dotenv import load_dotenv
import os
```


```python
load_dotenv()

os.environ["AGENTOPS_API_KEY"] = os.getenv("AGENTOPS_API_KEY", "your_api_key_here")
os.environ["GEMINI_API_KEY"] = os.getenv("GEMINI_API_KEY", "your_gemini_api_key_here")
```


```python
# Initialize AgentOps and Gemini client
agentops.init(tags=["gemini-example", "agentops-example"])
client = genai.Client()
```


```python
# Test synchronous generation
print("Testing synchronous generation:")
response = client.models.generate_content(model="gemini-1.5-flash", contents="What are the three laws of robotics?")
print(response.text)
```


```python
# Test streaming generation
print("\nTesting streaming generation:")
response_stream = client.models.generate_content_stream(
    model="gemini-1.5-flash", contents="Explain the concept of machine learning in simple terms."
)

for chunk in response_stream:
    print(chunk.text, end="")
print()  # Add newline after streaming output

# Test another synchronous generation
print("\nTesting another synchronous generation:")
response = client.models.generate_content(
    model="gemini-1.5-flash", contents="What is the difference between supervised and unsupervised learning?"
)
print(response.text)
```


```python
# Example of token counting
print("\nTesting token counting:")
token_response = client.models.count_tokens(
    model="gemini-1.5-flash", contents="This is a test sentence to count tokens."
)
print(f"Token count: {token_response.total_tokens}")
```


<script type="module" src="/scripts/github_stars.js"></script>
<script type="module" src="/scripts/scroll-img-fadein-animation.js"></script>
<script type="module" src="/scripts/button_heartbeat_animation.js"></script>
<script type="module" src="/scripts/adjust_api_dynamically.js"></script>