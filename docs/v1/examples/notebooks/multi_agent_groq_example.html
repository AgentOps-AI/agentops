<!-- This file was generated by Pandoc -->
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>multi_agent_groq_example</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<div id="a2e266428cefc683" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<h1 id="multi-agent-support">Multi-Agent Support</h1>
<p>This is an example implementation of tracking events from two
separate agents</p>
</div>
<div id="7c566fac57d3b6ce" class="cell code" data-execution_count="1"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> agentops</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> agentops.agent <span class="im">import</span> track_agent</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> groq <span class="im">import</span> Groq</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, Markdown</span></code></pre></div>
</div>
<div id="9f8c52496c04693" class="cell code" data-execution_count="2"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>GROQ_API_KEY <span class="op">=</span> os.getenv(<span class="st">&quot;GROQ_API_KEY&quot;</span>, <span class="st">&quot;&lt;your_openai_key&gt;&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>AGENTOPS_API_KEY <span class="op">=</span> os.getenv(<span class="st">&quot;AGENTOPS_API_KEY&quot;</span>, <span class="st">&quot;&lt;your_agentops_key&gt;&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>logging.basicConfig(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    level<span class="op">=</span>logging.DEBUG</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># this will let us see that calls are assigned to an agent</span></span></code></pre></div>
</div>
<div id="af062552554d60ce" class="cell code" data-execution_count="3"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>agentops.init(AGENTOPS_API_KEY, tags<span class="op">=</span>[<span class="st">&quot;multi-agent-groq-notebook&quot;</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>groq_client <span class="op">=</span> Groq(api_key<span class="op">=</span>GROQ_API_KEY)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443
DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 &quot;POST /v2/create_session HTTP/11&quot; 200 204
ðŸ–‡ AgentOps: Session Replay: https://app.agentops.ai/drilldown?session_id=892edb44-774d-4f52-a9b8-4d4eada5b434
INFO:agentops:Session Replay: https://app.agentops.ai/drilldown?session_id=892edb44-774d-4f52-a9b8-4d4eada5b434
DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False
DEBUG:httpx:load_verify_locations cafile=&#39;/Users/manu_suryavansh/miniforge3/envs/agentsops_dev/lib/python3.11/site-packages/certifi/cacert.pem&#39;
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443
DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 &quot;POST /v2/create_events HTTP/11&quot; 200 9
</code></pre>
</div>
</div>
<div id="95d212546aaf1f82" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<p>Now lets create a few agents!</p>
</div>
<div id="727e3cc26ce3ec3" class="cell code" data-execution_count="4"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="at">@track_agent</span>(name<span class="op">=</span><span class="st">&quot;qa&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QaAgent:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> completion(<span class="va">self</span>, prompt: <span class="bu">str</span>):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> groq_client.chat.completions.create(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span><span class="st">&quot;llama3-70b-8192&quot;</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>[</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                {</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;content&quot;</span>: <span class="st">&quot;You are a qa engineer and only output python code, no markdown tags.&quot;</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                },</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: prompt},</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> res.choices[<span class="dv">0</span>].message.content</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="at">@track_agent</span>(name<span class="op">=</span><span class="st">&quot;engineer&quot;</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EngineerAgent:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> completion(<span class="va">self</span>, prompt: <span class="bu">str</span>):</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> groq_client.chat.completions.create(</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span><span class="st">&quot;llama3-70b-8192&quot;</span>,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>[</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>                {</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>,</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;content&quot;</span>: <span class="st">&quot;You are a software engineer and only output python code, no markdown tags.&quot;</span>,</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>                },</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>                {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: prompt},</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> res.choices[<span class="dv">0</span>].message.content</span></code></pre></div>
</div>
<div id="79b75d65de738522" class="cell code" data-execution_count="5"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>qa <span class="op">=</span> QaAgent()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>engineer <span class="op">=</span> EngineerAgent()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443
DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 &quot;POST /v2/create_agent HTTP/11&quot; 200 9
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443
DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 &quot;POST /v2/create_agent HTTP/11&quot; 200 9
</code></pre>
</div>
</div>
<div id="69dd3af9206308cc" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<p>Now we have our agents and we tagged them with the
<code>@track_agent</code> decorator. Any LLM calls that go through this
class will now be tagged as agent calls in AgentOps.</p>
<p>Lets use these agents!</p>
</div>
<div id="7272b927-67ef-4b8c-84a5-63ed06f75aa5" class="cell code"
data-execution_count="6">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>generated_func <span class="op">=</span> engineer.completion(<span class="st">&quot;python function to test prime number&quot;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>DEBUG:groq._base_client:Request options: {&#39;method&#39;: &#39;post&#39;, &#39;url&#39;: &#39;/openai/v1/chat/completions&#39;, &#39;files&#39;: None, &#39;json_data&#39;: {&#39;messages&#39;: [{&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;You are a software engineer and only output python code, no markdown tags.&#39;}, {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;python function to test prime number&#39;}], &#39;model&#39;: &#39;llama3-70b-8192&#39;, &#39;temperature&#39;: 0.5}}
DEBUG:groq._base_client:Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
DEBUG:httpcore.connection:connect_tcp.started host=&#39;api.groq.com&#39; port=443 local_address=None timeout=5.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x108dc1010&gt;
DEBUG:httpcore.connection:start_tls.started ssl_context=&lt;ssl.SSLContext object at 0x10a6e4d40&gt; server_hostname=&#39;api.groq.com&#39; timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1098df650&gt;
DEBUG:httpcore.http11:send_request_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&#39;HTTP/1.1&#39;, 200, b&#39;OK&#39;, [(b&#39;Date&#39;, b&#39;Sun, 21 Jul 2024 05:55:22 GMT&#39;), (b&#39;Content-Type&#39;, b&#39;application/json&#39;), (b&#39;Transfer-Encoding&#39;, b&#39;chunked&#39;), (b&#39;Connection&#39;, b&#39;keep-alive&#39;), (b&#39;Cache-Control&#39;, b&#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;), (b&#39;vary&#39;, b&#39;Origin&#39;), (b&#39;x-ratelimit-limit-requests&#39;, b&#39;50000&#39;), (b&#39;x-ratelimit-limit-tokens&#39;, b&#39;30000&#39;), (b&#39;x-ratelimit-remaining-requests&#39;, b&#39;49999&#39;), (b&#39;x-ratelimit-remaining-tokens&#39;, b&#39;29963&#39;), (b&#39;x-ratelimit-reset-requests&#39;, b&#39;1.728s&#39;), (b&#39;x-ratelimit-reset-tokens&#39;, b&#39;74ms&#39;), (b&#39;x-request-id&#39;, b&#39;req_01j39xqscce4dbg5h08vrftym2&#39;), (b&#39;via&#39;, b&#39;1.1 google&#39;), (b&#39;alt-svc&#39;, b&#39;h3=&quot;:443&quot;; ma=86400&#39;), (b&#39;CF-Cache-Status&#39;, b&#39;DYNAMIC&#39;), (b&#39;Set-Cookie&#39;, b&#39;__cf_bm=vDBNcm.4NuP7B9MJyHy7WVBS7CVF.SyvXXsf7ZXdpT8-1721541322-1.0.1.1-QRg7ZBBgC845heu3O2ZfJySw1nqhlOCwpF29NmD1H9xnMUNFOstcyHCHabYKSBZXq6iNGbkYaId01XpPYOfuWQ; path=/; expires=Sun, 21-Jul-24 06:25:22 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None&#39;), (b&#39;Server&#39;, b&#39;cloudflare&#39;), (b&#39;CF-RAY&#39;, b&#39;8a68f10f2ba89652-SJC&#39;), (b&#39;Content-Encoding&#39;, b&#39;gzip&#39;)])
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &quot;HTTP/1.1 200 OK&quot;
DEBUG:httpcore.http11:receive_response_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:groq._base_client:HTTP Response: POST https://api.groq.com/openai/v1/chat/completions &quot;200 OK&quot; Headers({&#39;date&#39;: &#39;Sun, 21 Jul 2024 05:55:22 GMT&#39;, &#39;content-type&#39;: &#39;application/json&#39;, &#39;transfer-encoding&#39;: &#39;chunked&#39;, &#39;connection&#39;: &#39;keep-alive&#39;, &#39;cache-control&#39;: &#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;, &#39;vary&#39;: &#39;Origin&#39;, &#39;x-ratelimit-limit-requests&#39;: &#39;50000&#39;, &#39;x-ratelimit-limit-tokens&#39;: &#39;30000&#39;, &#39;x-ratelimit-remaining-requests&#39;: &#39;49999&#39;, &#39;x-ratelimit-remaining-tokens&#39;: &#39;29963&#39;, &#39;x-ratelimit-reset-requests&#39;: &#39;1.728s&#39;, &#39;x-ratelimit-reset-tokens&#39;: &#39;74ms&#39;, &#39;x-request-id&#39;: &#39;req_01j39xqscce4dbg5h08vrftym2&#39;, &#39;via&#39;: &#39;1.1 google&#39;, &#39;alt-svc&#39;: &#39;h3=&quot;:443&quot;; ma=86400&#39;, &#39;cf-cache-status&#39;: &#39;DYNAMIC&#39;, &#39;set-cookie&#39;: &#39;__cf_bm=vDBNcm.4NuP7B9MJyHy7WVBS7CVF.SyvXXsf7ZXdpT8-1721541322-1.0.1.1-QRg7ZBBgC845heu3O2ZfJySw1nqhlOCwpF29NmD1H9xnMUNFOstcyHCHabYKSBZXq6iNGbkYaId01XpPYOfuWQ; path=/; expires=Sun, 21-Jul-24 06:25:22 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None&#39;, &#39;server&#39;: &#39;cloudflare&#39;, &#39;cf-ray&#39;: &#39;8a68f10f2ba89652-SJC&#39;, &#39;content-encoding&#39;: &#39;gzip&#39;})
</code></pre>
</div>
</div>
<div id="830b86dac47dceb3" class="cell code" data-execution_count="7"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>display(Markdown(<span class="st">&quot;```python</span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> generated_func <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">```&quot;</span>))</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Markdown object&gt;</code></pre>
</div>
</div>
<div id="63c9d0d457aee91a" class="cell code" data-execution_count="8"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>generated_test <span class="op">=</span> qa.completion(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Write a python unit test that test the following function: </span><span class="ch">\n</span><span class="st"> &quot;</span> <span class="op">+</span> generated_func</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>DEBUG:groq._base_client:Request options: {&#39;method&#39;: &#39;post&#39;, &#39;url&#39;: &#39;/openai/v1/chat/completions&#39;, &#39;files&#39;: None, &#39;json_data&#39;: {&#39;messages&#39;: [{&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;You are a qa engineer and only output python code, no markdown tags.&#39;}, {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Write a python unit test that test the following function: \n def is_prime(n):\n    if n &lt;= 1:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    max_divisor = int(n**0.5) + 1\n    for d in range(3, max_divisor, 2):\n        if n % d == 0:\n            return False\n    return True&#39;}], &#39;model&#39;: &#39;llama3-70b-8192&#39;, &#39;temperature&#39;: 0.5}}
DEBUG:groq._base_client:Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&#39;HTTP/1.1&#39;, 200, b&#39;OK&#39;, [(b&#39;Date&#39;, b&#39;Sun, 21 Jul 2024 05:55:23 GMT&#39;), (b&#39;Content-Type&#39;, b&#39;application/json&#39;), (b&#39;Transfer-Encoding&#39;, b&#39;chunked&#39;), (b&#39;Connection&#39;, b&#39;keep-alive&#39;), (b&#39;Cache-Control&#39;, b&#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;), (b&#39;vary&#39;, b&#39;Origin&#39;), (b&#39;x-ratelimit-limit-requests&#39;, b&#39;50000&#39;), (b&#39;x-ratelimit-limit-tokens&#39;, b&#39;30000&#39;), (b&#39;x-ratelimit-remaining-requests&#39;, b&#39;49998&#39;), (b&#39;x-ratelimit-remaining-tokens&#39;, b&#39;29845&#39;), (b&#39;x-ratelimit-reset-requests&#39;, b&#39;2.960999999s&#39;), (b&#39;x-ratelimit-reset-tokens&#39;, b&#39;310ms&#39;), (b&#39;x-request-id&#39;, b&#39;req_01j39xqsy5fxgth4w9q6r24h9w&#39;), (b&#39;via&#39;, b&#39;1.1 google&#39;), (b&#39;alt-svc&#39;, b&#39;h3=&quot;:443&quot;; ma=86400&#39;), (b&#39;CF-Cache-Status&#39;, b&#39;DYNAMIC&#39;), (b&#39;Server&#39;, b&#39;cloudflare&#39;), (b&#39;CF-RAY&#39;, b&#39;8a68f112be2c9652-SJC&#39;), (b&#39;Content-Encoding&#39;, b&#39;gzip&#39;)])
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &quot;HTTP/1.1 200 OK&quot;
DEBUG:httpcore.http11:receive_response_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:groq._base_client:HTTP Response: POST https://api.groq.com/openai/v1/chat/completions &quot;200 OK&quot; Headers({&#39;date&#39;: &#39;Sun, 21 Jul 2024 05:55:23 GMT&#39;, &#39;content-type&#39;: &#39;application/json&#39;, &#39;transfer-encoding&#39;: &#39;chunked&#39;, &#39;connection&#39;: &#39;keep-alive&#39;, &#39;cache-control&#39;: &#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;, &#39;vary&#39;: &#39;Origin&#39;, &#39;x-ratelimit-limit-requests&#39;: &#39;50000&#39;, &#39;x-ratelimit-limit-tokens&#39;: &#39;30000&#39;, &#39;x-ratelimit-remaining-requests&#39;: &#39;49998&#39;, &#39;x-ratelimit-remaining-tokens&#39;: &#39;29845&#39;, &#39;x-ratelimit-reset-requests&#39;: &#39;2.960999999s&#39;, &#39;x-ratelimit-reset-tokens&#39;: &#39;310ms&#39;, &#39;x-request-id&#39;: &#39;req_01j39xqsy5fxgth4w9q6r24h9w&#39;, &#39;via&#39;: &#39;1.1 google&#39;, &#39;alt-svc&#39;: &#39;h3=&quot;:443&quot;; ma=86400&#39;, &#39;cf-cache-status&#39;: &#39;DYNAMIC&#39;, &#39;server&#39;: &#39;cloudflare&#39;, &#39;cf-ray&#39;: &#39;8a68f112be2c9652-SJC&#39;, &#39;content-encoding&#39;: &#39;gzip&#39;})
</code></pre>
</div>
</div>
<div id="a88ffcbd2015d422" class="cell code" data-execution_count="9"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>display(Markdown(<span class="st">&quot;```python</span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> generated_test <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">```&quot;</span>))</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Markdown object&gt;</code></pre>
</div>
</div>
<div id="1bd312ed049a5511" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<p>Perfect! It generated the code as expected, and in the DEBUG logs,
you can see that the calls were made by agents named "engineer" and
"qa"!</p>
</div>
<div id="cbd0817a31756397" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<p>Lets verify one more thing! If we make an LLM call outside of the
context of a tracked agent, we want to make sure it gets assigned to the
Default Agent.</p>
</div>
<div id="122e923cb07fd5f4" class="cell code" data-execution_count="10"
data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> groq_client.chat.completions.create(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;llama3-70b-8192&quot;</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;You are not a tracked agent&quot;</span>},</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Say hello&quot;</span>},</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>res.choices[<span class="dv">0</span>].message.content</span></code></pre></div>
<div class="output stream stderr">
<pre><code>DEBUG:groq._base_client:Request options: {&#39;method&#39;: &#39;post&#39;, &#39;url&#39;: &#39;/openai/v1/chat/completions&#39;, &#39;files&#39;: None, &#39;json_data&#39;: {&#39;messages&#39;: [{&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;You are not a tracked agent&#39;}, {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Say hello&#39;}], &#39;model&#39;: &#39;llama3-70b-8192&#39;}}
DEBUG:groq._base_client:Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
DEBUG:httpcore.http11:send_request_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&#39;HTTP/1.1&#39;, 200, b&#39;OK&#39;, [(b&#39;Date&#39;, b&#39;Sun, 21 Jul 2024 05:55:24 GMT&#39;), (b&#39;Content-Type&#39;, b&#39;application/json&#39;), (b&#39;Transfer-Encoding&#39;, b&#39;chunked&#39;), (b&#39;Connection&#39;, b&#39;keep-alive&#39;), (b&#39;Cache-Control&#39;, b&#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;), (b&#39;vary&#39;, b&#39;Origin&#39;), (b&#39;x-ratelimit-limit-requests&#39;, b&#39;50000&#39;), (b&#39;x-ratelimit-limit-tokens&#39;, b&#39;30000&#39;), (b&#39;x-ratelimit-remaining-requests&#39;, b&#39;49998&#39;), (b&#39;x-ratelimit-remaining-tokens&#39;, b&#39;29982&#39;), (b&#39;x-ratelimit-reset-requests&#39;, b&#39;3.318s&#39;), (b&#39;x-ratelimit-reset-tokens&#39;, b&#39;36ms&#39;), (b&#39;x-request-id&#39;, b&#39;req_01j39xqvrgem4bfd3gqybths6c&#39;), (b&#39;via&#39;, b&#39;1.1 google&#39;), (b&#39;alt-svc&#39;, b&#39;h3=&quot;:443&quot;; ma=86400&#39;), (b&#39;CF-Cache-Status&#39;, b&#39;DYNAMIC&#39;), (b&#39;Server&#39;, b&#39;cloudflare&#39;), (b&#39;CF-RAY&#39;, b&#39;8a68f11e6dd59652-SJC&#39;), (b&#39;Content-Encoding&#39;, b&#39;gzip&#39;)])
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &quot;HTTP/1.1 200 OK&quot;
DEBUG:httpcore.http11:receive_response_body.started request=&lt;Request [b&#39;POST&#39;]&gt;
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:groq._base_client:HTTP Response: POST https://api.groq.com/openai/v1/chat/completions &quot;200 OK&quot; Headers({&#39;date&#39;: &#39;Sun, 21 Jul 2024 05:55:24 GMT&#39;, &#39;content-type&#39;: &#39;application/json&#39;, &#39;transfer-encoding&#39;: &#39;chunked&#39;, &#39;connection&#39;: &#39;keep-alive&#39;, &#39;cache-control&#39;: &#39;private, max-age=0, no-store, no-cache, must-revalidate&#39;, &#39;vary&#39;: &#39;Origin&#39;, &#39;x-ratelimit-limit-requests&#39;: &#39;50000&#39;, &#39;x-ratelimit-limit-tokens&#39;: &#39;30000&#39;, &#39;x-ratelimit-remaining-requests&#39;: &#39;49998&#39;, &#39;x-ratelimit-remaining-tokens&#39;: &#39;29982&#39;, &#39;x-ratelimit-reset-requests&#39;: &#39;3.318s&#39;, &#39;x-ratelimit-reset-tokens&#39;: &#39;36ms&#39;, &#39;x-request-id&#39;: &#39;req_01j39xqvrgem4bfd3gqybths6c&#39;, &#39;via&#39;: &#39;1.1 google&#39;, &#39;alt-svc&#39;: &#39;h3=&quot;:443&quot;; ma=86400&#39;, &#39;cf-cache-status&#39;: &#39;DYNAMIC&#39;, &#39;server&#39;: &#39;cloudflare&#39;, &#39;cf-ray&#39;: &#39;8a68f11e6dd59652-SJC&#39;, &#39;content-encoding&#39;: &#39;gzip&#39;})
</code></pre>
</div>
<div class="output execute_result" data-execution_count="10">
<pre><code>&#39;Hello!&#39;</code></pre>
</div>
</div>
<div id="a30909020c6a1ada" class="cell markdown" data-collapsed="false"
data-jupyter="{&quot;outputs_hidden&quot;:false}">
<p>You'll notice that we didn't log an agent name, so the AgentOps
backend will assign it to the Default Agent for the session!</p>
</div>
<div id="d7a167c1-61f3-4499-8790-ec001e361e39" class="cell code">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
