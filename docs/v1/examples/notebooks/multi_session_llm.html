<!-- This file was generated by Pandoc -->
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>multi_session_llm</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://app.agentops.ai/notebook_styles.css" />
</head>
<body>
<div id="a0fe80a38dec2f7b" class="cell markdown" data-collapsed="false">
<h1 id="multiple-concurrent-sessions">Multiple Concurrent Sessions</h1>
<p>This example will show you how to run multiple sessions concurrently,
assigning LLM cals to a specific session.</p>
</div>
<div id="initial_id" class="cell code" data-collapsed="true">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> agentops</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> agentops <span class="im">import</span> ActionEvent</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span></code></pre></div>
</div>
<div id="da9cf64965c86ee9" class="cell markdown" data-collapsed="false">
<p>First, of course, lets init AgentOps. We're going to bypass creating
a session automatically for the sake of showing it below.</p>
</div>
<div id="39af2cd027ce268" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>agentops.init(auto_start_session<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>openai <span class="op">=</span> OpenAI()</span></code></pre></div>
</div>
<div id="9501d298aec35510" class="cell markdown" data-collapsed="false">
<p>Now lets create two sessions, each with an identifiable tag.</p>
</div>
<div id="4f24d06dd29579ff" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>session_1 <span class="op">=</span> agentops.start_session(tags<span class="op">=</span>[<span class="st">&quot;multi-session-test-1&quot;</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>session_2 <span class="op">=</span> agentops.start_session(tags<span class="op">=</span>[<span class="st">&quot;multi-session-test-2&quot;</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;session_id_1: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(session_1.session_id))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;session_id_2: </span><span class="sc">{}</span><span class="st">&quot;</span>.<span class="bu">format</span>(session_2.session_id))</span></code></pre></div>
</div>
<div id="38f373b7a8878a68" class="cell markdown" data-collapsed="false">
<h2 id="llm-calls">LLM Calls</h2>
<p>Now lets go ahead and make our first OpenAI LLM call. The challenge
with having multiple sessions at the same time is that there is no way
for AgentOps to know what LLM call is intended to pertain to what active
session. This means we need to do a little extra work in one of two
ways.</p>
</div>
<div id="8a2d65f5fcdb137" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [{<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Hello&quot;</span>}]</span></code></pre></div>
</div>
<div id="e1859e37b65669b2" class="cell markdown" data-collapsed="false">
<h3 id="patching-function">Patching Function</h3>
<p>This method involves wrapping the LLM call withing a function on
session. It can look a little counter-intuitive, but it easily tells us
what session the call belongs to.</p>
</div>
<div id="106a1c899602bd33" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># option 1: use session.patch</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> session_1.patch(openai.chat.completions.create)(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>messages,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="3e129661929e8368" class="cell markdown" data-collapsed="false">
<h3 id="create-patched-function">Create patched function</h3>
<p>If you're using the create function multiple times, you can create a
new function with the same method</p>
</div>
<div id="be3b866ee04ef767" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>observed_create <span class="op">=</span> session_1.patch(openai.chat.completions.create)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>obs_response <span class="op">=</span> observed_create(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>messages,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="ec03dbfb7a185d1d" class="cell markdown" data-collapsed="false">
<h3 id="keyword-argument">Keyword Argument</h3>
<p>Alternatively, you can also pass the session into the LLM function
call as a keyword argument. While this method works and is a bit more
readable, it is not a "pythonic" pattern and can lead to linting errors
in the code, as the base function is not expecting a
<code>session</code> keyword.</p>
</div>
<div id="4ad4c7629509b4be" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># option 2: add session as a keyword argument</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>response2 <span class="op">=</span> openai.chat.completions.create(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;gpt-3.5-turbo&quot;</span>, messages<span class="op">=</span>messages, temperature<span class="op">=</span><span class="fl">0.5</span>, session<span class="op">=</span>session_2</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="e6de84850aa2e135" class="cell markdown" data-collapsed="false">
<h2 id="recording-events">Recording Events</h2>
<p>Outside of LLM calls, there are plenty of other events that we want
to track. You can learn more about these events <a
href="https://docs.agentops.ai/v1/concepts/events">here</a>.</p>
<p>Recording these events on a session is as simple as
<code>session.record(...)</code></p>
</div>
<div id="964e3073bac33223" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>session_1.record(ActionEvent(action_type<span class="op">=</span><span class="st">&quot;test event&quot;</span>))</span></code></pre></div>
</div>
<div id="43ac0b9b99eab5c7" class="cell markdown" data-collapsed="false">
<p>Now let's go ahead and end the sessions</p>
</div>
<div id="7e3050abcb72421b" class="cell code" data-collapsed="false">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>session_1.end_session(end_state<span class="op">=</span><span class="st">&quot;Success&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>session_2.end_session(end_state<span class="op">=</span><span class="st">&quot;Success&quot;</span>)</span></code></pre></div>
</div>
<div id="53ea2b8dfee6270a" class="cell markdown" data-collapsed="false">
<p>If you look in the AgentOps dashboard for these sessions, you will
see two unique sessions, both with one LLM Event each, one with an
Action Event as well.</p>
</div>
<div id="dbc7483434f8c147" class="cell markdown" data-collapsed="false">

</div>
</body>
</html>
