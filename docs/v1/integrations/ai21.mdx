---
title: AI21
description: "Use AI21's latest models with AgentOps including:
Jamba 1.5, Jamba Instruct, and specialized task models"
---

## AI21

From [AI21's docs](https://docs.ai21.com/):

AI21 provides state-of-the-art language models through a simple API, offering:
- Multiple model sizes to balance performance and cost
- Specialized models for specific tasks like contextual answers
- Chat and completion endpoints
- Enterprise-grade reliability and support

AI21 supports several [models](https://docs.ai21.com/reference/models) including Jamba 1.5, Jamba Instruct, and task-specific models.

## Using AgentOps with AI21

### Requires `ai21>=2.0.0`

AgentOps works seamlessly with AI21's Python SDK. Here's how to use it:

```python
from ai21 import AI21Client
from ai21.models.chat import ChatMessage
import agentops

# Initialize clients
client = AI21Client(api_key="your-api-key")
agentops.init("your-agentops-key")

# Create your messages
messages = [
    ChatMessage(
        content="You are a world renowned poet in the style of Edgar Allan Poe.",
        role="system",
    ),
    ChatMessage(
        content="Write me a short poem about AI agents.",
        role="user",
    ),
]

# Make the API call
response = client.chat.completions.create(
    messages=messages,
    model="jamba-1.5-mini",
)
print(response.choices[0].message.content)
```

### Streaming Support

AI21 supports streaming responses:

```python
response = ""
stream_response = client.chat.completions.create(
    messages=messages,
    model="jamba-instruct",
    stream=True,
)

for chunk in stream_response:
    response += chunk.choices[0].delta.content
```

### Async Support

You can also use AI21 models asynchronously:

```python
from ai21 import AsyncAI21Client

aclient = AsyncAI21Client(api_key="your-api-key")

async def main():
    async_response = await aclient.chat.completions.create(
        messages=messages,
        model="jamba-1.5-mini",
    )
    print(async_response.choices[0].message.content)

await main()
```

### Task-Specific Models

AI21 provides specialized models for specific tasks. Here's an example using the contextual answers endpoint:

```python
response = client.answer.create(
    context="Your context text here...",
    question="Your question here?",
)
print(response.answer)
```

You can also stream answers:

```python
response = client.answer.create(
    context="Your context text here...",
    question="Your question here?",
    stream=True,
)
print(response.answer)
```

<script type="module" src="/scripts/github_stars.js"></script>
<script type="module" src="/scripts/link_to_api_button.js"></script>
<script type="module" src="/scripts/scroll-img-fadein-animation.js"></script>
<script type="module" src="/scripts/button_heartbeat_animation.js"></script>
<script type="css" src="/styles/styles.css"></script>
<script type="module" src="/scripts/adjust_api_dynamically.js"></script> 