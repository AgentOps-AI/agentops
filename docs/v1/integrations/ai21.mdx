---
title: AI21
description: "Use AI21's latest models with AgentOps including:
Jamba 1.5, Jamba Instruct, and specialized task models"
---

import CodeTooltip from '/snippets/add-code-tooltip.mdx'
import EnvTooltip from '/snippets/add-env-tooltip.mdx'

## AI21

From [AI21's docs](https://docs.ai21.com/):

AI21 provides state-of-the-art language models through a simple API, offering:
- Multiple model sizes to balance performance and cost
- Specialized models for specific tasks like contextual answers
- Chat and completion endpoints
- Enterprise-grade reliability and support

AI21 supports several including Jamba 1.5, Jamba Instruct, and task-specific models.

## Using AgentOps with AI21

### Requires `ai21>=2.0.0`

AgentOps works seamlessly with AI21's Python SDK. Here's how to use it:

<Steps>
  <Step title="Install the AgentOps SDK">
    <CodeGroup>
      ```bash pip 
      pip install agentops
      ```
      ```bash poetry
      poetry add agentops
      ```
    </CodeGroup>
  </Step>
  <Step title="Add AgentOps to your code">
    <CodeTooltip/>
    <span className="api-key-container">
      <CodeGroup>
        ```python python
        from ai21 import AI21Client
        from ai21.models.chat import ChatMessage
        import agentops

        # Initialize clients
        agentops.init(<INSERT YOUR API KEY HERE>)
        client = AI21Client(api_key="your-api-key")

        # Your AI21 code here...

        agentops.end_session("Success") # Success|Fail|Indeterminate
        ```
      </CodeGroup>
    </span>
    <EnvTooltip />
    <span className="api-key-container">
      <CodeGroup>
        ```python .env
        AGENTOPS_API_KEY=<YOUR API KEY>
        ```
      </CodeGroup>
      Read more about environment variables in [Advanced Configuration](/v1/usage/advanced-configuration)
    </span>
  </Step>
  <Step title="Run your Agent">
    Execute your program and visit [app.agentops.ai/drilldown](https://app.agentops.ai/drilldown) to observe your Agent! üïµÔ∏è
    <Tip>
      After your run, AgentOps prints a clickable url to console linking directly to your session in the Dashboard
    </Tip>
    <div/>{/* Intentionally blank div for newline */}
    <Frame type="glass" caption="Clickable link to session">
      <img height="200" src="https://github.com/AgentOps-AI/agentops/blob/cf67191f13e0e2a09446a61b7393e1810b3eee95/docs/images/link-to-session.gif?raw=true" />
    </Frame>
  </Step>
</Steps>

### Streaming Support

AI21 supports streaming responses:

```python
response = ""
stream_response = client.chat.completions.create(
    messages=messages,
    model="jamba-instruct",
    stream=True,
)

for chunk in stream_response:
    response += str(chunk.choices[0].delta.content)
```

### Async Support

You can also use AI21 models asynchronously:

```python
from ai21 import AsyncAI21Client

aclient = AsyncAI21Client(api_key="your-api-key")

async def main():
    async_response = await aclient.chat.completions.create(
        messages=messages,
        model="jamba-1.5-mini",
    )
    print(async_response.choices[0].message.content)

await main()
```

### Task-Specific Models

AI21 provides specialized models for specific tasks. Here's an example using the contextual answers endpoint:

```python
response = client.answer.create(
    context="Your context text here...",
    question="Your question here?",
)
print(response.answer)
```

You can also stream answers:

```python
response = client.answer.create(
    context="Your context text here...",
    question="Your question here?",
    stream=True,
)
print(response.answer)
```

<script type="module" src="/scripts/github_stars.js"></script>
<script type="module" src="/scripts/link_to_api_button.js"></script>
<script type="module" src="/scripts/scroll-img-fadein-animation.js"></script>
<script type="module" src="/scripts/button_heartbeat_animation.js"></script>
<script type="css" src="/styles/styles.css"></script>
<script type="module" src="/scripts/adjust_api_dynamically.js"></script> 